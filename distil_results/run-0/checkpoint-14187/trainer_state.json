{
  "best_metric": 0.42247602343559265,
  "best_model_checkpoint": "./distil_results\\run-0\\checkpoint-9458",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 14187,
  "is_hyper_param_search": true,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010573059843518714,
      "grad_norm": 2.4666976928710938,
      "learning_rate": 2.1330289238941094e-05,
      "loss": 0.6779,
      "step": 50
    },
    {
      "epoch": 0.02114611968703743,
      "grad_norm": 3.694483995437622,
      "learning_rate": 2.1254847882079874e-05,
      "loss": 0.675,
      "step": 100
    },
    {
      "epoch": 0.03171917953055614,
      "grad_norm": 6.4158196449279785,
      "learning_rate": 2.1179406525218655e-05,
      "loss": 0.6482,
      "step": 150
    },
    {
      "epoch": 0.04229223937407486,
      "grad_norm": 4.311564922332764,
      "learning_rate": 2.110396516835744e-05,
      "loss": 0.6382,
      "step": 200
    },
    {
      "epoch": 0.05286529921759357,
      "grad_norm": 4.418744087219238,
      "learning_rate": 2.102852381149622e-05,
      "loss": 0.5871,
      "step": 250
    },
    {
      "epoch": 0.06343835906111228,
      "grad_norm": 3.9597091674804688,
      "learning_rate": 2.0953082454635e-05,
      "loss": 0.6027,
      "step": 300
    },
    {
      "epoch": 0.074011418904631,
      "grad_norm": 11.2103271484375,
      "learning_rate": 2.087764109777378e-05,
      "loss": 0.5306,
      "step": 350
    },
    {
      "epoch": 0.08458447874814971,
      "grad_norm": 4.442270278930664,
      "learning_rate": 2.0802199740912563e-05,
      "loss": 0.5737,
      "step": 400
    },
    {
      "epoch": 0.09515753859166842,
      "grad_norm": 3.256399393081665,
      "learning_rate": 2.0726758384051343e-05,
      "loss": 0.6236,
      "step": 450
    },
    {
      "epoch": 0.10573059843518715,
      "grad_norm": 9.64320182800293,
      "learning_rate": 2.065131702719012e-05,
      "loss": 0.6228,
      "step": 500
    },
    {
      "epoch": 0.11630365827870585,
      "grad_norm": 3.2946910858154297,
      "learning_rate": 2.0575875670328904e-05,
      "loss": 0.5914,
      "step": 550
    },
    {
      "epoch": 0.12687671812222456,
      "grad_norm": 11.649035453796387,
      "learning_rate": 2.0500434313467684e-05,
      "loss": 0.574,
      "step": 600
    },
    {
      "epoch": 0.13744977796574329,
      "grad_norm": 5.2252960205078125,
      "learning_rate": 2.0424992956606468e-05,
      "loss": 0.5397,
      "step": 650
    },
    {
      "epoch": 0.148022837809262,
      "grad_norm": 4.026394844055176,
      "learning_rate": 2.0349551599745244e-05,
      "loss": 0.6091,
      "step": 700
    },
    {
      "epoch": 0.1585958976527807,
      "grad_norm": 8.355131149291992,
      "learning_rate": 2.0274110242884028e-05,
      "loss": 0.5782,
      "step": 750
    },
    {
      "epoch": 0.16916895749629943,
      "grad_norm": 3.7679693698883057,
      "learning_rate": 2.019866888602281e-05,
      "loss": 0.5428,
      "step": 800
    },
    {
      "epoch": 0.17974201733981815,
      "grad_norm": 3.9283180236816406,
      "learning_rate": 2.012322752916159e-05,
      "loss": 0.5879,
      "step": 850
    },
    {
      "epoch": 0.19031507718333684,
      "grad_norm": 8.321825981140137,
      "learning_rate": 2.004778617230037e-05,
      "loss": 0.5636,
      "step": 900
    },
    {
      "epoch": 0.20088813702685557,
      "grad_norm": 10.056607246398926,
      "learning_rate": 1.997234481543915e-05,
      "loss": 0.5436,
      "step": 950
    },
    {
      "epoch": 0.2114611968703743,
      "grad_norm": 7.2559733390808105,
      "learning_rate": 1.9896903458577933e-05,
      "loss": 0.5982,
      "step": 1000
    },
    {
      "epoch": 0.222034256713893,
      "grad_norm": 2.738114595413208,
      "learning_rate": 1.9821462101716713e-05,
      "loss": 0.52,
      "step": 1050
    },
    {
      "epoch": 0.2326073165574117,
      "grad_norm": 6.955148220062256,
      "learning_rate": 1.9746020744855493e-05,
      "loss": 0.5378,
      "step": 1100
    },
    {
      "epoch": 0.24318037640093043,
      "grad_norm": 7.953941822052002,
      "learning_rate": 1.9670579387994274e-05,
      "loss": 0.5336,
      "step": 1150
    },
    {
      "epoch": 0.2537534362444491,
      "grad_norm": 7.086467742919922,
      "learning_rate": 1.9595138031133057e-05,
      "loss": 0.5635,
      "step": 1200
    },
    {
      "epoch": 0.2643264960879679,
      "grad_norm": 8.470197677612305,
      "learning_rate": 1.9519696674271834e-05,
      "loss": 0.5527,
      "step": 1250
    },
    {
      "epoch": 0.27489955593148657,
      "grad_norm": 5.725771427154541,
      "learning_rate": 1.9444255317410614e-05,
      "loss": 0.5356,
      "step": 1300
    },
    {
      "epoch": 0.28547261577500527,
      "grad_norm": 7.357840061187744,
      "learning_rate": 1.9368813960549398e-05,
      "loss": 0.5391,
      "step": 1350
    },
    {
      "epoch": 0.296045675618524,
      "grad_norm": 6.478299617767334,
      "learning_rate": 1.929337260368818e-05,
      "loss": 0.5595,
      "step": 1400
    },
    {
      "epoch": 0.3066187354620427,
      "grad_norm": 3.3922934532165527,
      "learning_rate": 1.921793124682696e-05,
      "loss": 0.5732,
      "step": 1450
    },
    {
      "epoch": 0.3171917953055614,
      "grad_norm": 7.2494893074035645,
      "learning_rate": 1.914248988996574e-05,
      "loss": 0.5215,
      "step": 1500
    },
    {
      "epoch": 0.32776485514908016,
      "grad_norm": 6.902097702026367,
      "learning_rate": 1.9067048533104523e-05,
      "loss": 0.5075,
      "step": 1550
    },
    {
      "epoch": 0.33833791499259885,
      "grad_norm": 9.727093696594238,
      "learning_rate": 1.8991607176243303e-05,
      "loss": 0.5202,
      "step": 1600
    },
    {
      "epoch": 0.34891097483611755,
      "grad_norm": 10.47758960723877,
      "learning_rate": 1.8916165819382083e-05,
      "loss": 0.5032,
      "step": 1650
    },
    {
      "epoch": 0.3594840346796363,
      "grad_norm": 8.068986892700195,
      "learning_rate": 1.8840724462520863e-05,
      "loss": 0.5562,
      "step": 1700
    },
    {
      "epoch": 0.370057094523155,
      "grad_norm": 10.651673316955566,
      "learning_rate": 1.8765283105659644e-05,
      "loss": 0.5534,
      "step": 1750
    },
    {
      "epoch": 0.3806301543666737,
      "grad_norm": 6.058019161224365,
      "learning_rate": 1.8689841748798427e-05,
      "loss": 0.5718,
      "step": 1800
    },
    {
      "epoch": 0.39120321421019244,
      "grad_norm": 3.0268146991729736,
      "learning_rate": 1.8614400391937204e-05,
      "loss": 0.5056,
      "step": 1850
    },
    {
      "epoch": 0.40177627405371114,
      "grad_norm": 5.338146209716797,
      "learning_rate": 1.8538959035075988e-05,
      "loss": 0.5381,
      "step": 1900
    },
    {
      "epoch": 0.4123493338972299,
      "grad_norm": 9.605704307556152,
      "learning_rate": 1.8463517678214768e-05,
      "loss": 0.519,
      "step": 1950
    },
    {
      "epoch": 0.4229223937407486,
      "grad_norm": 6.523146152496338,
      "learning_rate": 1.838807632135355e-05,
      "loss": 0.5353,
      "step": 2000
    },
    {
      "epoch": 0.4334954535842673,
      "grad_norm": 3.1398067474365234,
      "learning_rate": 1.831263496449233e-05,
      "loss": 0.5125,
      "step": 2050
    },
    {
      "epoch": 0.444068513427786,
      "grad_norm": 11.838757514953613,
      "learning_rate": 1.8237193607631112e-05,
      "loss": 0.5026,
      "step": 2100
    },
    {
      "epoch": 0.4546415732713047,
      "grad_norm": 8.337739944458008,
      "learning_rate": 1.8161752250769893e-05,
      "loss": 0.5106,
      "step": 2150
    },
    {
      "epoch": 0.4652146331148234,
      "grad_norm": 7.869847297668457,
      "learning_rate": 1.8086310893908673e-05,
      "loss": 0.5271,
      "step": 2200
    },
    {
      "epoch": 0.47578769295834217,
      "grad_norm": 5.7856950759887695,
      "learning_rate": 1.8010869537047453e-05,
      "loss": 0.4733,
      "step": 2250
    },
    {
      "epoch": 0.48636075280186086,
      "grad_norm": 7.644218921661377,
      "learning_rate": 1.7935428180186233e-05,
      "loss": 0.5056,
      "step": 2300
    },
    {
      "epoch": 0.49693381264537956,
      "grad_norm": 6.295045375823975,
      "learning_rate": 1.7859986823325017e-05,
      "loss": 0.478,
      "step": 2350
    },
    {
      "epoch": 0.5075068724888983,
      "grad_norm": 5.3759355545043945,
      "learning_rate": 1.7784545466463794e-05,
      "loss": 0.5292,
      "step": 2400
    },
    {
      "epoch": 0.518079932332417,
      "grad_norm": 9.562654495239258,
      "learning_rate": 1.7709104109602578e-05,
      "loss": 0.4766,
      "step": 2450
    },
    {
      "epoch": 0.5286529921759358,
      "grad_norm": 2.059211254119873,
      "learning_rate": 1.7633662752741358e-05,
      "loss": 0.5577,
      "step": 2500
    },
    {
      "epoch": 0.5392260520194544,
      "grad_norm": 3.3371741771698,
      "learning_rate": 1.7558221395880138e-05,
      "loss": 0.4903,
      "step": 2550
    },
    {
      "epoch": 0.5497991118629731,
      "grad_norm": 6.96537446975708,
      "learning_rate": 1.748278003901892e-05,
      "loss": 0.5216,
      "step": 2600
    },
    {
      "epoch": 0.5603721717064919,
      "grad_norm": 12.757112503051758,
      "learning_rate": 1.74073386821577e-05,
      "loss": 0.547,
      "step": 2650
    },
    {
      "epoch": 0.5709452315500105,
      "grad_norm": 7.996160984039307,
      "learning_rate": 1.7331897325296482e-05,
      "loss": 0.5227,
      "step": 2700
    },
    {
      "epoch": 0.5815182913935293,
      "grad_norm": 10.81688117980957,
      "learning_rate": 1.7256455968435263e-05,
      "loss": 0.5246,
      "step": 2750
    },
    {
      "epoch": 0.592091351237048,
      "grad_norm": 5.784497261047363,
      "learning_rate": 1.7181014611574043e-05,
      "loss": 0.5063,
      "step": 2800
    },
    {
      "epoch": 0.6026644110805667,
      "grad_norm": 5.527698040008545,
      "learning_rate": 1.7105573254712823e-05,
      "loss": 0.5079,
      "step": 2850
    },
    {
      "epoch": 0.6132374709240854,
      "grad_norm": 7.221369743347168,
      "learning_rate": 1.7030131897851607e-05,
      "loss": 0.4922,
      "step": 2900
    },
    {
      "epoch": 0.6238105307676042,
      "grad_norm": 4.170981407165527,
      "learning_rate": 1.6954690540990387e-05,
      "loss": 0.4631,
      "step": 2950
    },
    {
      "epoch": 0.6343835906111228,
      "grad_norm": 2.997122287750244,
      "learning_rate": 1.6879249184129167e-05,
      "loss": 0.4891,
      "step": 3000
    },
    {
      "epoch": 0.6449566504546416,
      "grad_norm": 3.317134141921997,
      "learning_rate": 1.6803807827267948e-05,
      "loss": 0.5361,
      "step": 3050
    },
    {
      "epoch": 0.6555297102981603,
      "grad_norm": 9.707466125488281,
      "learning_rate": 1.6728366470406728e-05,
      "loss": 0.4875,
      "step": 3100
    },
    {
      "epoch": 0.666102770141679,
      "grad_norm": 9.83971118927002,
      "learning_rate": 1.6652925113545508e-05,
      "loss": 0.5514,
      "step": 3150
    },
    {
      "epoch": 0.6766758299851977,
      "grad_norm": 9.338716506958008,
      "learning_rate": 1.657748375668429e-05,
      "loss": 0.4895,
      "step": 3200
    },
    {
      "epoch": 0.6872488898287165,
      "grad_norm": 2.9440112113952637,
      "learning_rate": 1.6502042399823072e-05,
      "loss": 0.4823,
      "step": 3250
    },
    {
      "epoch": 0.6978219496722351,
      "grad_norm": 14.791674613952637,
      "learning_rate": 1.6426601042961852e-05,
      "loss": 0.4743,
      "step": 3300
    },
    {
      "epoch": 0.7083950095157538,
      "grad_norm": 3.2558584213256836,
      "learning_rate": 1.6351159686100633e-05,
      "loss": 0.4709,
      "step": 3350
    },
    {
      "epoch": 0.7189680693592726,
      "grad_norm": 6.650009632110596,
      "learning_rate": 1.6275718329239413e-05,
      "loss": 0.4542,
      "step": 3400
    },
    {
      "epoch": 0.7295411292027912,
      "grad_norm": 8.48292350769043,
      "learning_rate": 1.6200276972378196e-05,
      "loss": 0.5402,
      "step": 3450
    },
    {
      "epoch": 0.74011418904631,
      "grad_norm": 7.751077651977539,
      "learning_rate": 1.6124835615516977e-05,
      "loss": 0.4947,
      "step": 3500
    },
    {
      "epoch": 0.7506872488898287,
      "grad_norm": 3.1062896251678467,
      "learning_rate": 1.6049394258655754e-05,
      "loss": 0.4554,
      "step": 3550
    },
    {
      "epoch": 0.7612603087333474,
      "grad_norm": 7.0531415939331055,
      "learning_rate": 1.5973952901794537e-05,
      "loss": 0.5189,
      "step": 3600
    },
    {
      "epoch": 0.7718333685768661,
      "grad_norm": 9.115802764892578,
      "learning_rate": 1.5898511544933318e-05,
      "loss": 0.4151,
      "step": 3650
    },
    {
      "epoch": 0.7824064284203849,
      "grad_norm": 4.491584777832031,
      "learning_rate": 1.5823070188072098e-05,
      "loss": 0.5119,
      "step": 3700
    },
    {
      "epoch": 0.7929794882639035,
      "grad_norm": 18.249792098999023,
      "learning_rate": 1.5747628831210878e-05,
      "loss": 0.4936,
      "step": 3750
    },
    {
      "epoch": 0.8035525481074223,
      "grad_norm": 8.93071460723877,
      "learning_rate": 1.5672187474349662e-05,
      "loss": 0.4496,
      "step": 3800
    },
    {
      "epoch": 0.814125607950941,
      "grad_norm": 11.072824478149414,
      "learning_rate": 1.5596746117488442e-05,
      "loss": 0.4429,
      "step": 3850
    },
    {
      "epoch": 0.8246986677944598,
      "grad_norm": 2.28176212310791,
      "learning_rate": 1.5521304760627222e-05,
      "loss": 0.452,
      "step": 3900
    },
    {
      "epoch": 0.8352717276379784,
      "grad_norm": 0.5334054827690125,
      "learning_rate": 1.5445863403766003e-05,
      "loss": 0.5174,
      "step": 3950
    },
    {
      "epoch": 0.8458447874814972,
      "grad_norm": 10.664823532104492,
      "learning_rate": 1.5370422046904783e-05,
      "loss": 0.4718,
      "step": 4000
    },
    {
      "epoch": 0.8564178473250159,
      "grad_norm": 3.7231082916259766,
      "learning_rate": 1.5294980690043566e-05,
      "loss": 0.4733,
      "step": 4050
    },
    {
      "epoch": 0.8669909071685346,
      "grad_norm": 2.055471420288086,
      "learning_rate": 1.5219539333182345e-05,
      "loss": 0.428,
      "step": 4100
    },
    {
      "epoch": 0.8775639670120533,
      "grad_norm": 9.685327529907227,
      "learning_rate": 1.5144097976321127e-05,
      "loss": 0.4573,
      "step": 4150
    },
    {
      "epoch": 0.888137026855572,
      "grad_norm": 4.0107550621032715,
      "learning_rate": 1.5068656619459907e-05,
      "loss": 0.4712,
      "step": 4200
    },
    {
      "epoch": 0.8987100866990907,
      "grad_norm": 4.092140197753906,
      "learning_rate": 1.499321526259869e-05,
      "loss": 0.4344,
      "step": 4250
    },
    {
      "epoch": 0.9092831465426094,
      "grad_norm": 5.453145980834961,
      "learning_rate": 1.491777390573747e-05,
      "loss": 0.4967,
      "step": 4300
    },
    {
      "epoch": 0.9198562063861282,
      "grad_norm": 6.099764347076416,
      "learning_rate": 1.484233254887625e-05,
      "loss": 0.4773,
      "step": 4350
    },
    {
      "epoch": 0.9304292662296468,
      "grad_norm": 5.3555588722229,
      "learning_rate": 1.4766891192015032e-05,
      "loss": 0.482,
      "step": 4400
    },
    {
      "epoch": 0.9410023260731656,
      "grad_norm": 3.868960380554199,
      "learning_rate": 1.469144983515381e-05,
      "loss": 0.454,
      "step": 4450
    },
    {
      "epoch": 0.9515753859166843,
      "grad_norm": 8.971285820007324,
      "learning_rate": 1.4616008478292594e-05,
      "loss": 0.5162,
      "step": 4500
    },
    {
      "epoch": 0.962148445760203,
      "grad_norm": 7.144505977630615,
      "learning_rate": 1.4540567121431373e-05,
      "loss": 0.412,
      "step": 4550
    },
    {
      "epoch": 0.9727215056037217,
      "grad_norm": 13.30410099029541,
      "learning_rate": 1.4465125764570154e-05,
      "loss": 0.4579,
      "step": 4600
    },
    {
      "epoch": 0.9832945654472405,
      "grad_norm": 3.4991743564605713,
      "learning_rate": 1.4389684407708935e-05,
      "loss": 0.3995,
      "step": 4650
    },
    {
      "epoch": 0.9938676252907591,
      "grad_norm": 12.339458465576172,
      "learning_rate": 1.4314243050847717e-05,
      "loss": 0.4895,
      "step": 4700
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.7979488263903574,
      "eval_f1": 0.7976701658087613,
      "eval_loss": 0.4514825642108917,
      "eval_runtime": 45.5085,
      "eval_samples_per_second": 207.829,
      "eval_steps_per_second": 25.995,
      "step": 4729
    },
    {
      "epoch": 1.0044406851342778,
      "grad_norm": 11.332819938659668,
      "learning_rate": 1.4238801693986497e-05,
      "loss": 0.4082,
      "step": 4750
    },
    {
      "epoch": 1.0150137449777965,
      "grad_norm": 3.20015287399292,
      "learning_rate": 1.4163360337125277e-05,
      "loss": 0.3053,
      "step": 4800
    },
    {
      "epoch": 1.0255868048213153,
      "grad_norm": 11.529474258422852,
      "learning_rate": 1.408791898026406e-05,
      "loss": 0.3887,
      "step": 4850
    },
    {
      "epoch": 1.036159864664834,
      "grad_norm": 9.15365982055664,
      "learning_rate": 1.401247762340284e-05,
      "loss": 0.3608,
      "step": 4900
    },
    {
      "epoch": 1.0467329245083528,
      "grad_norm": 6.521333694458008,
      "learning_rate": 1.3937036266541621e-05,
      "loss": 0.3825,
      "step": 4950
    },
    {
      "epoch": 1.0573059843518715,
      "grad_norm": 11.063582420349121,
      "learning_rate": 1.3861594909680402e-05,
      "loss": 0.3983,
      "step": 5000
    },
    {
      "epoch": 1.06787904419539,
      "grad_norm": 5.61434268951416,
      "learning_rate": 1.3786153552819184e-05,
      "loss": 0.3498,
      "step": 5050
    },
    {
      "epoch": 1.0784521040389088,
      "grad_norm": 4.973913669586182,
      "learning_rate": 1.3710712195957962e-05,
      "loss": 0.3668,
      "step": 5100
    },
    {
      "epoch": 1.0890251638824275,
      "grad_norm": 21.636411666870117,
      "learning_rate": 1.3635270839096746e-05,
      "loss": 0.3535,
      "step": 5150
    },
    {
      "epoch": 1.0995982237259463,
      "grad_norm": 9.988651275634766,
      "learning_rate": 1.3559829482235524e-05,
      "loss": 0.3895,
      "step": 5200
    },
    {
      "epoch": 1.110171283569465,
      "grad_norm": 11.765693664550781,
      "learning_rate": 1.3484388125374305e-05,
      "loss": 0.3898,
      "step": 5250
    },
    {
      "epoch": 1.1207443434129838,
      "grad_norm": 7.365621089935303,
      "learning_rate": 1.3408946768513087e-05,
      "loss": 0.391,
      "step": 5300
    },
    {
      "epoch": 1.1313174032565025,
      "grad_norm": 9.2944974899292,
      "learning_rate": 1.3333505411651867e-05,
      "loss": 0.3753,
      "step": 5350
    },
    {
      "epoch": 1.141890463100021,
      "grad_norm": 6.930461883544922,
      "learning_rate": 1.3258064054790649e-05,
      "loss": 0.3699,
      "step": 5400
    },
    {
      "epoch": 1.1524635229435398,
      "grad_norm": 13.272493362426758,
      "learning_rate": 1.318262269792943e-05,
      "loss": 0.3431,
      "step": 5450
    },
    {
      "epoch": 1.1630365827870586,
      "grad_norm": 3.0938267707824707,
      "learning_rate": 1.3107181341068211e-05,
      "loss": 0.2686,
      "step": 5500
    },
    {
      "epoch": 1.1736096426305773,
      "grad_norm": 5.654418468475342,
      "learning_rate": 1.3031739984206991e-05,
      "loss": 0.3984,
      "step": 5550
    },
    {
      "epoch": 1.184182702474096,
      "grad_norm": 8.964588165283203,
      "learning_rate": 1.2956298627345773e-05,
      "loss": 0.3153,
      "step": 5600
    },
    {
      "epoch": 1.1947557623176146,
      "grad_norm": 9.440595626831055,
      "learning_rate": 1.2880857270484554e-05,
      "loss": 0.3961,
      "step": 5650
    },
    {
      "epoch": 1.2053288221611334,
      "grad_norm": 2.14886212348938,
      "learning_rate": 1.2805415913623332e-05,
      "loss": 0.399,
      "step": 5700
    },
    {
      "epoch": 1.215901882004652,
      "grad_norm": 15.050630569458008,
      "learning_rate": 1.2729974556762116e-05,
      "loss": 0.3332,
      "step": 5750
    },
    {
      "epoch": 1.2264749418481709,
      "grad_norm": 12.321399688720703,
      "learning_rate": 1.2654533199900894e-05,
      "loss": 0.357,
      "step": 5800
    },
    {
      "epoch": 1.2370480016916896,
      "grad_norm": 8.873641014099121,
      "learning_rate": 1.2579091843039676e-05,
      "loss": 0.3658,
      "step": 5850
    },
    {
      "epoch": 1.2476210615352084,
      "grad_norm": 14.641634941101074,
      "learning_rate": 1.2503650486178457e-05,
      "loss": 0.3314,
      "step": 5900
    },
    {
      "epoch": 1.258194121378727,
      "grad_norm": 12.548749923706055,
      "learning_rate": 1.2428209129317239e-05,
      "loss": 0.3399,
      "step": 5950
    },
    {
      "epoch": 1.2687671812222456,
      "grad_norm": 6.017930507659912,
      "learning_rate": 1.2352767772456019e-05,
      "loss": 0.3602,
      "step": 6000
    },
    {
      "epoch": 1.2793402410657644,
      "grad_norm": 40.1791877746582,
      "learning_rate": 1.2277326415594801e-05,
      "loss": 0.3692,
      "step": 6050
    },
    {
      "epoch": 1.2899133009092831,
      "grad_norm": 38.49607467651367,
      "learning_rate": 1.2201885058733581e-05,
      "loss": 0.2877,
      "step": 6100
    },
    {
      "epoch": 1.3004863607528019,
      "grad_norm": 14.93587589263916,
      "learning_rate": 1.2126443701872361e-05,
      "loss": 0.3617,
      "step": 6150
    },
    {
      "epoch": 1.3110594205963206,
      "grad_norm": 5.4458537101745605,
      "learning_rate": 1.2051002345011143e-05,
      "loss": 0.3331,
      "step": 6200
    },
    {
      "epoch": 1.3216324804398392,
      "grad_norm": 34.96612548828125,
      "learning_rate": 1.1975560988149924e-05,
      "loss": 0.3605,
      "step": 6250
    },
    {
      "epoch": 1.3322055402833581,
      "grad_norm": 28.63680648803711,
      "learning_rate": 1.1900119631288706e-05,
      "loss": 0.3381,
      "step": 6300
    },
    {
      "epoch": 1.3427786001268767,
      "grad_norm": 8.905688285827637,
      "learning_rate": 1.1824678274427484e-05,
      "loss": 0.2961,
      "step": 6350
    },
    {
      "epoch": 1.3533516599703954,
      "grad_norm": 14.07498836517334,
      "learning_rate": 1.1749236917566268e-05,
      "loss": 0.3534,
      "step": 6400
    },
    {
      "epoch": 1.3639247198139142,
      "grad_norm": 15.06459903717041,
      "learning_rate": 1.1673795560705046e-05,
      "loss": 0.38,
      "step": 6450
    },
    {
      "epoch": 1.374497779657433,
      "grad_norm": 4.868040084838867,
      "learning_rate": 1.1598354203843827e-05,
      "loss": 0.328,
      "step": 6500
    },
    {
      "epoch": 1.3850708395009517,
      "grad_norm": 13.050298690795898,
      "learning_rate": 1.1522912846982609e-05,
      "loss": 0.3503,
      "step": 6550
    },
    {
      "epoch": 1.3956438993444702,
      "grad_norm": 14.185402870178223,
      "learning_rate": 1.1447471490121389e-05,
      "loss": 0.281,
      "step": 6600
    },
    {
      "epoch": 1.406216959187989,
      "grad_norm": 14.623916625976562,
      "learning_rate": 1.1372030133260171e-05,
      "loss": 0.2846,
      "step": 6650
    },
    {
      "epoch": 1.4167900190315077,
      "grad_norm": 16.512107849121094,
      "learning_rate": 1.1296588776398951e-05,
      "loss": 0.3442,
      "step": 6700
    },
    {
      "epoch": 1.4273630788750264,
      "grad_norm": 8.177905082702637,
      "learning_rate": 1.1221147419537733e-05,
      "loss": 0.312,
      "step": 6750
    },
    {
      "epoch": 1.4379361387185452,
      "grad_norm": 9.697278022766113,
      "learning_rate": 1.1145706062676513e-05,
      "loss": 0.3632,
      "step": 6800
    },
    {
      "epoch": 1.4485091985620637,
      "grad_norm": 24.097536087036133,
      "learning_rate": 1.1070264705815295e-05,
      "loss": 0.3149,
      "step": 6850
    },
    {
      "epoch": 1.4590822584055827,
      "grad_norm": 3.080275297164917,
      "learning_rate": 1.0994823348954076e-05,
      "loss": 0.3165,
      "step": 6900
    },
    {
      "epoch": 1.4696553182491012,
      "grad_norm": 1.215409278869629,
      "learning_rate": 1.0919381992092854e-05,
      "loss": 0.3197,
      "step": 6950
    },
    {
      "epoch": 1.48022837809262,
      "grad_norm": 15.369301795959473,
      "learning_rate": 1.0843940635231636e-05,
      "loss": 0.344,
      "step": 7000
    },
    {
      "epoch": 1.4908014379361387,
      "grad_norm": 11.350268363952637,
      "learning_rate": 1.0768499278370416e-05,
      "loss": 0.4046,
      "step": 7050
    },
    {
      "epoch": 1.5013744977796575,
      "grad_norm": 29.472158432006836,
      "learning_rate": 1.0693057921509198e-05,
      "loss": 0.3679,
      "step": 7100
    },
    {
      "epoch": 1.5119475576231762,
      "grad_norm": 14.808784484863281,
      "learning_rate": 1.0617616564647979e-05,
      "loss": 0.3811,
      "step": 7150
    },
    {
      "epoch": 1.5225206174666948,
      "grad_norm": 17.979473114013672,
      "learning_rate": 1.0542175207786759e-05,
      "loss": 0.3426,
      "step": 7200
    },
    {
      "epoch": 1.5330936773102137,
      "grad_norm": 4.896825790405273,
      "learning_rate": 1.0466733850925541e-05,
      "loss": 0.3155,
      "step": 7250
    },
    {
      "epoch": 1.5436667371537323,
      "grad_norm": 10.3132963180542,
      "learning_rate": 1.0391292494064321e-05,
      "loss": 0.3177,
      "step": 7300
    },
    {
      "epoch": 1.554239796997251,
      "grad_norm": 0.36288687586784363,
      "learning_rate": 1.0315851137203103e-05,
      "loss": 0.2914,
      "step": 7350
    },
    {
      "epoch": 1.5648128568407698,
      "grad_norm": 5.665973663330078,
      "learning_rate": 1.0240409780341883e-05,
      "loss": 0.374,
      "step": 7400
    },
    {
      "epoch": 1.5753859166842883,
      "grad_norm": 27.743349075317383,
      "learning_rate": 1.0164968423480665e-05,
      "loss": 0.3017,
      "step": 7450
    },
    {
      "epoch": 1.5859589765278073,
      "grad_norm": 8.944555282592773,
      "learning_rate": 1.0089527066619446e-05,
      "loss": 0.3191,
      "step": 7500
    },
    {
      "epoch": 1.5965320363713258,
      "grad_norm": 12.416226387023926,
      "learning_rate": 1.0014085709758228e-05,
      "loss": 0.3525,
      "step": 7550
    },
    {
      "epoch": 1.6071050962148445,
      "grad_norm": 2.7698752880096436,
      "learning_rate": 9.938644352897006e-06,
      "loss": 0.2815,
      "step": 7600
    },
    {
      "epoch": 1.6176781560583633,
      "grad_norm": 10.35041618347168,
      "learning_rate": 9.863202996035788e-06,
      "loss": 0.3669,
      "step": 7650
    },
    {
      "epoch": 1.628251215901882,
      "grad_norm": 22.18708038330078,
      "learning_rate": 9.787761639174568e-06,
      "loss": 0.3268,
      "step": 7700
    },
    {
      "epoch": 1.6388242757454008,
      "grad_norm": 11.469756126403809,
      "learning_rate": 9.71232028231335e-06,
      "loss": 0.3281,
      "step": 7750
    },
    {
      "epoch": 1.6493973355889193,
      "grad_norm": 30.72704315185547,
      "learning_rate": 9.63687892545213e-06,
      "loss": 0.3906,
      "step": 7800
    },
    {
      "epoch": 1.6599703954324383,
      "grad_norm": 3.5206563472747803,
      "learning_rate": 9.561437568590911e-06,
      "loss": 0.3334,
      "step": 7850
    },
    {
      "epoch": 1.6705434552759568,
      "grad_norm": 2.4067578315734863,
      "learning_rate": 9.485996211729693e-06,
      "loss": 0.3206,
      "step": 7900
    },
    {
      "epoch": 1.6811165151194756,
      "grad_norm": 2.1780807971954346,
      "learning_rate": 9.410554854868473e-06,
      "loss": 0.3275,
      "step": 7950
    },
    {
      "epoch": 1.6916895749629943,
      "grad_norm": 32.0942497253418,
      "learning_rate": 9.335113498007255e-06,
      "loss": 0.3214,
      "step": 8000
    },
    {
      "epoch": 1.7022626348065129,
      "grad_norm": 13.160368919372559,
      "learning_rate": 9.259672141146035e-06,
      "loss": 0.3368,
      "step": 8050
    },
    {
      "epoch": 1.7128356946500318,
      "grad_norm": 5.7556681632995605,
      "learning_rate": 9.184230784284816e-06,
      "loss": 0.3168,
      "step": 8100
    },
    {
      "epoch": 1.7234087544935504,
      "grad_norm": 0.46439459919929504,
      "learning_rate": 9.108789427423596e-06,
      "loss": 0.2779,
      "step": 8150
    },
    {
      "epoch": 1.733981814337069,
      "grad_norm": 14.79412841796875,
      "learning_rate": 9.033348070562378e-06,
      "loss": 0.3494,
      "step": 8200
    },
    {
      "epoch": 1.7445548741805879,
      "grad_norm": 19.774105072021484,
      "learning_rate": 8.957906713701158e-06,
      "loss": 0.3652,
      "step": 8250
    },
    {
      "epoch": 1.7551279340241066,
      "grad_norm": 3.69887375831604,
      "learning_rate": 8.88246535683994e-06,
      "loss": 0.3212,
      "step": 8300
    },
    {
      "epoch": 1.7657009938676254,
      "grad_norm": 15.437102317810059,
      "learning_rate": 8.80702399997872e-06,
      "loss": 0.274,
      "step": 8350
    },
    {
      "epoch": 1.7762740537111439,
      "grad_norm": 8.711307525634766,
      "learning_rate": 8.731582643117502e-06,
      "loss": 0.3476,
      "step": 8400
    },
    {
      "epoch": 1.7868471135546629,
      "grad_norm": 33.524208068847656,
      "learning_rate": 8.656141286256281e-06,
      "loss": 0.3201,
      "step": 8450
    },
    {
      "epoch": 1.7974201733981814,
      "grad_norm": 1.6866015195846558,
      "learning_rate": 8.580699929395063e-06,
      "loss": 0.2605,
      "step": 8500
    },
    {
      "epoch": 1.8079932332417001,
      "grad_norm": 29.806995391845703,
      "learning_rate": 8.505258572533843e-06,
      "loss": 0.3512,
      "step": 8550
    },
    {
      "epoch": 1.8185662930852189,
      "grad_norm": 8.674875259399414,
      "learning_rate": 8.429817215672625e-06,
      "loss": 0.3449,
      "step": 8600
    },
    {
      "epoch": 1.8291393529287374,
      "grad_norm": 10.03825855255127,
      "learning_rate": 8.354375858811405e-06,
      "loss": 0.3563,
      "step": 8650
    },
    {
      "epoch": 1.8397124127722564,
      "grad_norm": 43.245296478271484,
      "learning_rate": 8.278934501950187e-06,
      "loss": 0.3197,
      "step": 8700
    },
    {
      "epoch": 1.850285472615775,
      "grad_norm": 9.75916862487793,
      "learning_rate": 8.203493145088968e-06,
      "loss": 0.2965,
      "step": 8750
    },
    {
      "epoch": 1.8608585324592937,
      "grad_norm": 1.9368021488189697,
      "learning_rate": 8.128051788227748e-06,
      "loss": 0.3682,
      "step": 8800
    },
    {
      "epoch": 1.8714315923028124,
      "grad_norm": 0.8632673025131226,
      "learning_rate": 8.05261043136653e-06,
      "loss": 0.3256,
      "step": 8850
    },
    {
      "epoch": 1.8820046521463312,
      "grad_norm": 15.74034309387207,
      "learning_rate": 7.97716907450531e-06,
      "loss": 0.3402,
      "step": 8900
    },
    {
      "epoch": 1.89257771198985,
      "grad_norm": 14.778282165527344,
      "learning_rate": 7.90172771764409e-06,
      "loss": 0.2839,
      "step": 8950
    },
    {
      "epoch": 1.9031507718333684,
      "grad_norm": 11.413578987121582,
      "learning_rate": 7.826286360782872e-06,
      "loss": 0.3814,
      "step": 9000
    },
    {
      "epoch": 1.9137238316768874,
      "grad_norm": 5.070478916168213,
      "learning_rate": 7.750845003921653e-06,
      "loss": 0.3132,
      "step": 9050
    },
    {
      "epoch": 1.924296891520406,
      "grad_norm": 4.722480773925781,
      "learning_rate": 7.675403647060433e-06,
      "loss": 0.3397,
      "step": 9100
    },
    {
      "epoch": 1.9348699513639247,
      "grad_norm": 7.033731460571289,
      "learning_rate": 7.599962290199215e-06,
      "loss": 0.2696,
      "step": 9150
    },
    {
      "epoch": 1.9454430112074435,
      "grad_norm": 0.7234598398208618,
      "learning_rate": 7.524520933337996e-06,
      "loss": 0.3145,
      "step": 9200
    },
    {
      "epoch": 1.9560160710509622,
      "grad_norm": 32.051612854003906,
      "learning_rate": 7.449079576476776e-06,
      "loss": 0.2947,
      "step": 9250
    },
    {
      "epoch": 1.966589130894481,
      "grad_norm": 3.6746461391448975,
      "learning_rate": 7.373638219615557e-06,
      "loss": 0.3269,
      "step": 9300
    },
    {
      "epoch": 1.9771621907379995,
      "grad_norm": 0.8911247849464417,
      "learning_rate": 7.298196862754338e-06,
      "loss": 0.3785,
      "step": 9350
    },
    {
      "epoch": 1.9877352505815185,
      "grad_norm": 1.9131745100021362,
      "learning_rate": 7.222755505893119e-06,
      "loss": 0.3136,
      "step": 9400
    },
    {
      "epoch": 1.998308310425037,
      "grad_norm": 34.7707633972168,
      "learning_rate": 7.1473141490319e-06,
      "loss": 0.3432,
      "step": 9450
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8458447874814972,
      "eval_f1": 0.8457687526932212,
      "eval_loss": 0.42247602343559265,
      "eval_runtime": 75.0249,
      "eval_samples_per_second": 126.065,
      "eval_steps_per_second": 15.768,
      "step": 9458
    },
    {
      "epoch": 2.0088813702685555,
      "grad_norm": 35.12796401977539,
      "learning_rate": 7.07187279217068e-06,
      "loss": 0.2254,
      "step": 9500
    },
    {
      "epoch": 2.0194544301120745,
      "grad_norm": 8.617981910705566,
      "learning_rate": 6.996431435309461e-06,
      "loss": 0.1909,
      "step": 9550
    },
    {
      "epoch": 2.030027489955593,
      "grad_norm": 62.89641571044922,
      "learning_rate": 6.920990078448242e-06,
      "loss": 0.2275,
      "step": 9600
    },
    {
      "epoch": 2.040600549799112,
      "grad_norm": 5.18789005279541,
      "learning_rate": 6.8455487215870234e-06,
      "loss": 0.1784,
      "step": 9650
    },
    {
      "epoch": 2.0511736096426305,
      "grad_norm": 55.782203674316406,
      "learning_rate": 6.7701073647258046e-06,
      "loss": 0.1919,
      "step": 9700
    },
    {
      "epoch": 2.0617466694861495,
      "grad_norm": 12.813902854919434,
      "learning_rate": 6.694666007864584e-06,
      "loss": 0.176,
      "step": 9750
    },
    {
      "epoch": 2.072319729329668,
      "grad_norm": 29.885982513427734,
      "learning_rate": 6.619224651003365e-06,
      "loss": 0.242,
      "step": 9800
    },
    {
      "epoch": 2.0828927891731865,
      "grad_norm": 0.5377352237701416,
      "learning_rate": 6.543783294142146e-06,
      "loss": 0.1966,
      "step": 9850
    },
    {
      "epoch": 2.0934658490167055,
      "grad_norm": 0.4820437431335449,
      "learning_rate": 6.468341937280927e-06,
      "loss": 0.2349,
      "step": 9900
    },
    {
      "epoch": 2.104038908860224,
      "grad_norm": 0.13617461919784546,
      "learning_rate": 6.3929005804197084e-06,
      "loss": 0.1739,
      "step": 9950
    },
    {
      "epoch": 2.114611968703743,
      "grad_norm": 11.102762222290039,
      "learning_rate": 6.3174592235584896e-06,
      "loss": 0.2479,
      "step": 10000
    },
    {
      "epoch": 2.1251850285472615,
      "grad_norm": 15.35348892211914,
      "learning_rate": 6.242017866697271e-06,
      "loss": 0.2197,
      "step": 10050
    },
    {
      "epoch": 2.13575808839078,
      "grad_norm": 3.6089348793029785,
      "learning_rate": 6.166576509836052e-06,
      "loss": 0.246,
      "step": 10100
    },
    {
      "epoch": 2.146331148234299,
      "grad_norm": 0.12299633771181107,
      "learning_rate": 6.091135152974832e-06,
      "loss": 0.1413,
      "step": 10150
    },
    {
      "epoch": 2.1569042080778176,
      "grad_norm": 0.3407686650753021,
      "learning_rate": 6.015693796113612e-06,
      "loss": 0.2486,
      "step": 10200
    },
    {
      "epoch": 2.1674772679213365,
      "grad_norm": 38.143226623535156,
      "learning_rate": 5.9402524392523934e-06,
      "loss": 0.2294,
      "step": 10250
    },
    {
      "epoch": 2.178050327764855,
      "grad_norm": 51.159385681152344,
      "learning_rate": 5.8648110823911746e-06,
      "loss": 0.2296,
      "step": 10300
    },
    {
      "epoch": 2.188623387608374,
      "grad_norm": 0.3020786643028259,
      "learning_rate": 5.789369725529956e-06,
      "loss": 0.2565,
      "step": 10350
    },
    {
      "epoch": 2.1991964474518926,
      "grad_norm": 15.623955726623535,
      "learning_rate": 5.713928368668736e-06,
      "loss": 0.253,
      "step": 10400
    },
    {
      "epoch": 2.209769507295411,
      "grad_norm": 12.814769744873047,
      "learning_rate": 5.638487011807517e-06,
      "loss": 0.305,
      "step": 10450
    },
    {
      "epoch": 2.22034256713893,
      "grad_norm": 53.102291107177734,
      "learning_rate": 5.563045654946298e-06,
      "loss": 0.1916,
      "step": 10500
    },
    {
      "epoch": 2.2309156269824486,
      "grad_norm": 37.61688995361328,
      "learning_rate": 5.487604298085079e-06,
      "loss": 0.2248,
      "step": 10550
    },
    {
      "epoch": 2.2414886868259676,
      "grad_norm": 0.25108465552330017,
      "learning_rate": 5.41216294122386e-06,
      "loss": 0.2184,
      "step": 10600
    },
    {
      "epoch": 2.252061746669486,
      "grad_norm": 0.829818844795227,
      "learning_rate": 5.336721584362641e-06,
      "loss": 0.2241,
      "step": 10650
    },
    {
      "epoch": 2.262634806513005,
      "grad_norm": 73.10518646240234,
      "learning_rate": 5.261280227501422e-06,
      "loss": 0.2138,
      "step": 10700
    },
    {
      "epoch": 2.2732078663565236,
      "grad_norm": 6.5424652099609375,
      "learning_rate": 5.185838870640202e-06,
      "loss": 0.2408,
      "step": 10750
    },
    {
      "epoch": 2.283780926200042,
      "grad_norm": 56.67356491088867,
      "learning_rate": 5.110397513778983e-06,
      "loss": 0.2132,
      "step": 10800
    },
    {
      "epoch": 2.294353986043561,
      "grad_norm": 0.5326321125030518,
      "learning_rate": 5.034956156917764e-06,
      "loss": 0.2142,
      "step": 10850
    },
    {
      "epoch": 2.3049270458870796,
      "grad_norm": 0.07507562637329102,
      "learning_rate": 4.959514800056545e-06,
      "loss": 0.2988,
      "step": 10900
    },
    {
      "epoch": 2.3155001057305986,
      "grad_norm": 38.21923065185547,
      "learning_rate": 4.884073443195326e-06,
      "loss": 0.2034,
      "step": 10950
    },
    {
      "epoch": 2.326073165574117,
      "grad_norm": 41.703556060791016,
      "learning_rate": 4.808632086334107e-06,
      "loss": 0.2514,
      "step": 11000
    },
    {
      "epoch": 2.3366462254176357,
      "grad_norm": 0.10168956220149994,
      "learning_rate": 4.733190729472888e-06,
      "loss": 0.2165,
      "step": 11050
    },
    {
      "epoch": 2.3472192852611546,
      "grad_norm": 73.0610580444336,
      "learning_rate": 4.657749372611669e-06,
      "loss": 0.1892,
      "step": 11100
    },
    {
      "epoch": 2.357792345104673,
      "grad_norm": 18.671445846557617,
      "learning_rate": 4.58230801575045e-06,
      "loss": 0.3595,
      "step": 11150
    },
    {
      "epoch": 2.368365404948192,
      "grad_norm": 0.16815771162509918,
      "learning_rate": 4.50686665888923e-06,
      "loss": 0.1784,
      "step": 11200
    },
    {
      "epoch": 2.3789384647917107,
      "grad_norm": 0.05683254450559616,
      "learning_rate": 4.4314253020280115e-06,
      "loss": 0.1727,
      "step": 11250
    },
    {
      "epoch": 2.389511524635229,
      "grad_norm": 17.154338836669922,
      "learning_rate": 4.355983945166793e-06,
      "loss": 0.2561,
      "step": 11300
    },
    {
      "epoch": 2.400084584478748,
      "grad_norm": 10.707240104675293,
      "learning_rate": 4.280542588305573e-06,
      "loss": 0.1973,
      "step": 11350
    },
    {
      "epoch": 2.4106576443222667,
      "grad_norm": 23.744726181030273,
      "learning_rate": 4.205101231444354e-06,
      "loss": 0.1437,
      "step": 11400
    },
    {
      "epoch": 2.4212307041657857,
      "grad_norm": 11.9781494140625,
      "learning_rate": 4.129659874583134e-06,
      "loss": 0.2468,
      "step": 11450
    },
    {
      "epoch": 2.431803764009304,
      "grad_norm": 1.0872446298599243,
      "learning_rate": 4.054218517721915e-06,
      "loss": 0.2023,
      "step": 11500
    },
    {
      "epoch": 2.442376823852823,
      "grad_norm": 0.12530671060085297,
      "learning_rate": 3.9787771608606965e-06,
      "loss": 0.277,
      "step": 11550
    },
    {
      "epoch": 2.4529498836963417,
      "grad_norm": 0.10959165543317795,
      "learning_rate": 3.903335803999477e-06,
      "loss": 0.1684,
      "step": 11600
    },
    {
      "epoch": 2.4635229435398607,
      "grad_norm": 0.16892915964126587,
      "learning_rate": 3.827894447138258e-06,
      "loss": 0.2621,
      "step": 11650
    },
    {
      "epoch": 2.474096003383379,
      "grad_norm": 3.4214563369750977,
      "learning_rate": 3.752453090277039e-06,
      "loss": 0.2273,
      "step": 11700
    },
    {
      "epoch": 2.4846690632268977,
      "grad_norm": 6.230865478515625,
      "learning_rate": 3.67701173341582e-06,
      "loss": 0.2128,
      "step": 11750
    },
    {
      "epoch": 2.4952421230704167,
      "grad_norm": 27.225671768188477,
      "learning_rate": 3.6015703765546012e-06,
      "loss": 0.2014,
      "step": 11800
    },
    {
      "epoch": 2.5058151829139352,
      "grad_norm": 0.06888584792613983,
      "learning_rate": 3.5261290196933815e-06,
      "loss": 0.2412,
      "step": 11850
    },
    {
      "epoch": 2.516388242757454,
      "grad_norm": 0.9860268235206604,
      "learning_rate": 3.4506876628321626e-06,
      "loss": 0.2049,
      "step": 11900
    },
    {
      "epoch": 2.5269613026009727,
      "grad_norm": 0.050066664814949036,
      "learning_rate": 3.3752463059709437e-06,
      "loss": 0.1919,
      "step": 11950
    },
    {
      "epoch": 2.5375343624444913,
      "grad_norm": 51.1694450378418,
      "learning_rate": 3.299804949109725e-06,
      "loss": 0.1733,
      "step": 12000
    },
    {
      "epoch": 2.5481074222880102,
      "grad_norm": 8.373244285583496,
      "learning_rate": 3.224363592248505e-06,
      "loss": 0.2869,
      "step": 12050
    },
    {
      "epoch": 2.5586804821315288,
      "grad_norm": 55.791927337646484,
      "learning_rate": 3.1489222353872862e-06,
      "loss": 0.2001,
      "step": 12100
    },
    {
      "epoch": 2.5692535419750477,
      "grad_norm": 14.959270477294922,
      "learning_rate": 3.073480878526067e-06,
      "loss": 0.2402,
      "step": 12150
    },
    {
      "epoch": 2.5798266018185663,
      "grad_norm": 39.87413024902344,
      "learning_rate": 2.998039521664848e-06,
      "loss": 0.3875,
      "step": 12200
    },
    {
      "epoch": 2.590399661662085,
      "grad_norm": 26.791027069091797,
      "learning_rate": 2.9225981648036287e-06,
      "loss": 0.2846,
      "step": 12250
    },
    {
      "epoch": 2.6009727215056038,
      "grad_norm": 14.29557991027832,
      "learning_rate": 2.8471568079424094e-06,
      "loss": 0.1888,
      "step": 12300
    },
    {
      "epoch": 2.6115457813491223,
      "grad_norm": 0.1781274676322937,
      "learning_rate": 2.7717154510811906e-06,
      "loss": 0.1826,
      "step": 12350
    },
    {
      "epoch": 2.6221188411926413,
      "grad_norm": 0.15433816611766815,
      "learning_rate": 2.6962740942199717e-06,
      "loss": 0.237,
      "step": 12400
    },
    {
      "epoch": 2.63269190103616,
      "grad_norm": 50.827510833740234,
      "learning_rate": 2.6208327373587524e-06,
      "loss": 0.2322,
      "step": 12450
    },
    {
      "epoch": 2.6432649608796783,
      "grad_norm": 2.674037456512451,
      "learning_rate": 2.5453913804975335e-06,
      "loss": 0.2124,
      "step": 12500
    },
    {
      "epoch": 2.6538380207231973,
      "grad_norm": 2.0887258052825928,
      "learning_rate": 2.469950023636314e-06,
      "loss": 0.2805,
      "step": 12550
    },
    {
      "epoch": 2.6644110805667163,
      "grad_norm": 3.43654465675354,
      "learning_rate": 2.394508666775095e-06,
      "loss": 0.2315,
      "step": 12600
    },
    {
      "epoch": 2.674984140410235,
      "grad_norm": 0.07432004809379578,
      "learning_rate": 2.3190673099138756e-06,
      "loss": 0.2987,
      "step": 12650
    },
    {
      "epoch": 2.6855572002537533,
      "grad_norm": 47.17211151123047,
      "learning_rate": 2.2436259530526567e-06,
      "loss": 0.2602,
      "step": 12700
    },
    {
      "epoch": 2.6961302600972723,
      "grad_norm": 0.39421215653419495,
      "learning_rate": 2.1681845961914374e-06,
      "loss": 0.1855,
      "step": 12750
    },
    {
      "epoch": 2.706703319940791,
      "grad_norm": 1.7015970945358276,
      "learning_rate": 2.0927432393302185e-06,
      "loss": 0.1919,
      "step": 12800
    },
    {
      "epoch": 2.71727637978431,
      "grad_norm": 65.25163269042969,
      "learning_rate": 2.017301882468999e-06,
      "loss": 0.228,
      "step": 12850
    },
    {
      "epoch": 2.7278494396278283,
      "grad_norm": 0.09103203564882278,
      "learning_rate": 1.9418605256077803e-06,
      "loss": 0.1866,
      "step": 12900
    },
    {
      "epoch": 2.738422499471347,
      "grad_norm": 32.375709533691406,
      "learning_rate": 1.866419168746561e-06,
      "loss": 0.1947,
      "step": 12950
    },
    {
      "epoch": 2.748995559314866,
      "grad_norm": 1.5135517120361328,
      "learning_rate": 1.7909778118853419e-06,
      "loss": 0.278,
      "step": 13000
    },
    {
      "epoch": 2.7595686191583844,
      "grad_norm": 0.03241501376032829,
      "learning_rate": 1.715536455024123e-06,
      "loss": 0.2165,
      "step": 13050
    },
    {
      "epoch": 2.7701416790019033,
      "grad_norm": 36.659950256347656,
      "learning_rate": 1.6400950981629037e-06,
      "loss": 0.2161,
      "step": 13100
    },
    {
      "epoch": 2.780714738845422,
      "grad_norm": 52.54340744018555,
      "learning_rate": 1.5646537413016848e-06,
      "loss": 0.2185,
      "step": 13150
    },
    {
      "epoch": 2.7912877986889404,
      "grad_norm": 54.91128158569336,
      "learning_rate": 1.4892123844404655e-06,
      "loss": 0.1768,
      "step": 13200
    },
    {
      "epoch": 2.8018608585324594,
      "grad_norm": 48.80651092529297,
      "learning_rate": 1.4137710275792464e-06,
      "loss": 0.2339,
      "step": 13250
    },
    {
      "epoch": 2.812433918375978,
      "grad_norm": 11.634398460388184,
      "learning_rate": 1.338329670718027e-06,
      "loss": 0.2174,
      "step": 13300
    },
    {
      "epoch": 2.823006978219497,
      "grad_norm": 18.7663516998291,
      "learning_rate": 1.2628883138568082e-06,
      "loss": 0.1341,
      "step": 13350
    },
    {
      "epoch": 2.8335800380630154,
      "grad_norm": 12.349392890930176,
      "learning_rate": 1.1874469569955891e-06,
      "loss": 0.2131,
      "step": 13400
    },
    {
      "epoch": 2.844153097906534,
      "grad_norm": 0.05044795200228691,
      "learning_rate": 1.11200560013437e-06,
      "loss": 0.2007,
      "step": 13450
    },
    {
      "epoch": 2.854726157750053,
      "grad_norm": 0.1329299956560135,
      "learning_rate": 1.0365642432731507e-06,
      "loss": 0.213,
      "step": 13500
    },
    {
      "epoch": 2.8652992175935714,
      "grad_norm": 31.928115844726562,
      "learning_rate": 9.611228864119316e-07,
      "loss": 0.2214,
      "step": 13550
    },
    {
      "epoch": 2.8758722774370904,
      "grad_norm": 0.3399638831615448,
      "learning_rate": 8.856815295507125e-07,
      "loss": 0.181,
      "step": 13600
    },
    {
      "epoch": 2.886445337280609,
      "grad_norm": 87.97957611083984,
      "learning_rate": 8.102401726894934e-07,
      "loss": 0.2662,
      "step": 13650
    },
    {
      "epoch": 2.8970183971241275,
      "grad_norm": 27.909147262573242,
      "learning_rate": 7.347988158282742e-07,
      "loss": 0.2297,
      "step": 13700
    },
    {
      "epoch": 2.9075914569676464,
      "grad_norm": 0.047761812806129456,
      "learning_rate": 6.593574589670551e-07,
      "loss": 0.3475,
      "step": 13750
    },
    {
      "epoch": 2.9181645168111654,
      "grad_norm": 12.235329627990723,
      "learning_rate": 5.83916102105836e-07,
      "loss": 0.2635,
      "step": 13800
    },
    {
      "epoch": 2.928737576654684,
      "grad_norm": 26.63043975830078,
      "learning_rate": 5.084747452446169e-07,
      "loss": 0.1651,
      "step": 13850
    },
    {
      "epoch": 2.9393106364982025,
      "grad_norm": 12.654474258422852,
      "learning_rate": 4.330333883833978e-07,
      "loss": 0.2939,
      "step": 13900
    },
    {
      "epoch": 2.9498836963417214,
      "grad_norm": 12.281573295593262,
      "learning_rate": 3.5759203152217863e-07,
      "loss": 0.2437,
      "step": 13950
    },
    {
      "epoch": 2.96045675618524,
      "grad_norm": 24.995397567749023,
      "learning_rate": 2.8215067466095953e-07,
      "loss": 0.1138,
      "step": 14000
    },
    {
      "epoch": 2.971029816028759,
      "grad_norm": 1.5706279277801514,
      "learning_rate": 2.0670931779974038e-07,
      "loss": 0.1838,
      "step": 14050
    },
    {
      "epoch": 2.9816028758722775,
      "grad_norm": 44.80591583251953,
      "learning_rate": 1.3126796093852126e-07,
      "loss": 0.2416,
      "step": 14100
    },
    {
      "epoch": 2.992175935715796,
      "grad_norm": 20.50546646118164,
      "learning_rate": 5.5826604077302146e-08,
      "loss": 0.1262,
      "step": 14150
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8547261577500529,
      "eval_f1": 0.854505894310172,
      "eval_loss": 0.6108450293540955,
      "eval_runtime": 77.1713,
      "eval_samples_per_second": 122.559,
      "eval_steps_per_second": 15.33,
      "step": 14187
    }
  ],
  "logging_steps": 50,
  "max_steps": 14187,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3748694914566144.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": {
    "learning_rate": 2.1405730595802314e-05,
    "num_train_epochs": 3,
    "per_device_train_batch_size": 8,
    "weight_decay": 0.053536818522940344
  }
}
