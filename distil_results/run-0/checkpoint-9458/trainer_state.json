{
  "best_metric": 0.42247602343559265,
  "best_model_checkpoint": "./distil_results\\run-0\\checkpoint-9458",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 9458,
  "is_hyper_param_search": true,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010573059843518714,
      "grad_norm": 2.4666976928710938,
      "learning_rate": 2.1330289238941094e-05,
      "loss": 0.6779,
      "step": 50
    },
    {
      "epoch": 0.02114611968703743,
      "grad_norm": 3.694483995437622,
      "learning_rate": 2.1254847882079874e-05,
      "loss": 0.675,
      "step": 100
    },
    {
      "epoch": 0.03171917953055614,
      "grad_norm": 6.4158196449279785,
      "learning_rate": 2.1179406525218655e-05,
      "loss": 0.6482,
      "step": 150
    },
    {
      "epoch": 0.04229223937407486,
      "grad_norm": 4.311564922332764,
      "learning_rate": 2.110396516835744e-05,
      "loss": 0.6382,
      "step": 200
    },
    {
      "epoch": 0.05286529921759357,
      "grad_norm": 4.418744087219238,
      "learning_rate": 2.102852381149622e-05,
      "loss": 0.5871,
      "step": 250
    },
    {
      "epoch": 0.06343835906111228,
      "grad_norm": 3.9597091674804688,
      "learning_rate": 2.0953082454635e-05,
      "loss": 0.6027,
      "step": 300
    },
    {
      "epoch": 0.074011418904631,
      "grad_norm": 11.2103271484375,
      "learning_rate": 2.087764109777378e-05,
      "loss": 0.5306,
      "step": 350
    },
    {
      "epoch": 0.08458447874814971,
      "grad_norm": 4.442270278930664,
      "learning_rate": 2.0802199740912563e-05,
      "loss": 0.5737,
      "step": 400
    },
    {
      "epoch": 0.09515753859166842,
      "grad_norm": 3.256399393081665,
      "learning_rate": 2.0726758384051343e-05,
      "loss": 0.6236,
      "step": 450
    },
    {
      "epoch": 0.10573059843518715,
      "grad_norm": 9.64320182800293,
      "learning_rate": 2.065131702719012e-05,
      "loss": 0.6228,
      "step": 500
    },
    {
      "epoch": 0.11630365827870585,
      "grad_norm": 3.2946910858154297,
      "learning_rate": 2.0575875670328904e-05,
      "loss": 0.5914,
      "step": 550
    },
    {
      "epoch": 0.12687671812222456,
      "grad_norm": 11.649035453796387,
      "learning_rate": 2.0500434313467684e-05,
      "loss": 0.574,
      "step": 600
    },
    {
      "epoch": 0.13744977796574329,
      "grad_norm": 5.2252960205078125,
      "learning_rate": 2.0424992956606468e-05,
      "loss": 0.5397,
      "step": 650
    },
    {
      "epoch": 0.148022837809262,
      "grad_norm": 4.026394844055176,
      "learning_rate": 2.0349551599745244e-05,
      "loss": 0.6091,
      "step": 700
    },
    {
      "epoch": 0.1585958976527807,
      "grad_norm": 8.355131149291992,
      "learning_rate": 2.0274110242884028e-05,
      "loss": 0.5782,
      "step": 750
    },
    {
      "epoch": 0.16916895749629943,
      "grad_norm": 3.7679693698883057,
      "learning_rate": 2.019866888602281e-05,
      "loss": 0.5428,
      "step": 800
    },
    {
      "epoch": 0.17974201733981815,
      "grad_norm": 3.9283180236816406,
      "learning_rate": 2.012322752916159e-05,
      "loss": 0.5879,
      "step": 850
    },
    {
      "epoch": 0.19031507718333684,
      "grad_norm": 8.321825981140137,
      "learning_rate": 2.004778617230037e-05,
      "loss": 0.5636,
      "step": 900
    },
    {
      "epoch": 0.20088813702685557,
      "grad_norm": 10.056607246398926,
      "learning_rate": 1.997234481543915e-05,
      "loss": 0.5436,
      "step": 950
    },
    {
      "epoch": 0.2114611968703743,
      "grad_norm": 7.2559733390808105,
      "learning_rate": 1.9896903458577933e-05,
      "loss": 0.5982,
      "step": 1000
    },
    {
      "epoch": 0.222034256713893,
      "grad_norm": 2.738114595413208,
      "learning_rate": 1.9821462101716713e-05,
      "loss": 0.52,
      "step": 1050
    },
    {
      "epoch": 0.2326073165574117,
      "grad_norm": 6.955148220062256,
      "learning_rate": 1.9746020744855493e-05,
      "loss": 0.5378,
      "step": 1100
    },
    {
      "epoch": 0.24318037640093043,
      "grad_norm": 7.953941822052002,
      "learning_rate": 1.9670579387994274e-05,
      "loss": 0.5336,
      "step": 1150
    },
    {
      "epoch": 0.2537534362444491,
      "grad_norm": 7.086467742919922,
      "learning_rate": 1.9595138031133057e-05,
      "loss": 0.5635,
      "step": 1200
    },
    {
      "epoch": 0.2643264960879679,
      "grad_norm": 8.470197677612305,
      "learning_rate": 1.9519696674271834e-05,
      "loss": 0.5527,
      "step": 1250
    },
    {
      "epoch": 0.27489955593148657,
      "grad_norm": 5.725771427154541,
      "learning_rate": 1.9444255317410614e-05,
      "loss": 0.5356,
      "step": 1300
    },
    {
      "epoch": 0.28547261577500527,
      "grad_norm": 7.357840061187744,
      "learning_rate": 1.9368813960549398e-05,
      "loss": 0.5391,
      "step": 1350
    },
    {
      "epoch": 0.296045675618524,
      "grad_norm": 6.478299617767334,
      "learning_rate": 1.929337260368818e-05,
      "loss": 0.5595,
      "step": 1400
    },
    {
      "epoch": 0.3066187354620427,
      "grad_norm": 3.3922934532165527,
      "learning_rate": 1.921793124682696e-05,
      "loss": 0.5732,
      "step": 1450
    },
    {
      "epoch": 0.3171917953055614,
      "grad_norm": 7.2494893074035645,
      "learning_rate": 1.914248988996574e-05,
      "loss": 0.5215,
      "step": 1500
    },
    {
      "epoch": 0.32776485514908016,
      "grad_norm": 6.902097702026367,
      "learning_rate": 1.9067048533104523e-05,
      "loss": 0.5075,
      "step": 1550
    },
    {
      "epoch": 0.33833791499259885,
      "grad_norm": 9.727093696594238,
      "learning_rate": 1.8991607176243303e-05,
      "loss": 0.5202,
      "step": 1600
    },
    {
      "epoch": 0.34891097483611755,
      "grad_norm": 10.47758960723877,
      "learning_rate": 1.8916165819382083e-05,
      "loss": 0.5032,
      "step": 1650
    },
    {
      "epoch": 0.3594840346796363,
      "grad_norm": 8.068986892700195,
      "learning_rate": 1.8840724462520863e-05,
      "loss": 0.5562,
      "step": 1700
    },
    {
      "epoch": 0.370057094523155,
      "grad_norm": 10.651673316955566,
      "learning_rate": 1.8765283105659644e-05,
      "loss": 0.5534,
      "step": 1750
    },
    {
      "epoch": 0.3806301543666737,
      "grad_norm": 6.058019161224365,
      "learning_rate": 1.8689841748798427e-05,
      "loss": 0.5718,
      "step": 1800
    },
    {
      "epoch": 0.39120321421019244,
      "grad_norm": 3.0268146991729736,
      "learning_rate": 1.8614400391937204e-05,
      "loss": 0.5056,
      "step": 1850
    },
    {
      "epoch": 0.40177627405371114,
      "grad_norm": 5.338146209716797,
      "learning_rate": 1.8538959035075988e-05,
      "loss": 0.5381,
      "step": 1900
    },
    {
      "epoch": 0.4123493338972299,
      "grad_norm": 9.605704307556152,
      "learning_rate": 1.8463517678214768e-05,
      "loss": 0.519,
      "step": 1950
    },
    {
      "epoch": 0.4229223937407486,
      "grad_norm": 6.523146152496338,
      "learning_rate": 1.838807632135355e-05,
      "loss": 0.5353,
      "step": 2000
    },
    {
      "epoch": 0.4334954535842673,
      "grad_norm": 3.1398067474365234,
      "learning_rate": 1.831263496449233e-05,
      "loss": 0.5125,
      "step": 2050
    },
    {
      "epoch": 0.444068513427786,
      "grad_norm": 11.838757514953613,
      "learning_rate": 1.8237193607631112e-05,
      "loss": 0.5026,
      "step": 2100
    },
    {
      "epoch": 0.4546415732713047,
      "grad_norm": 8.337739944458008,
      "learning_rate": 1.8161752250769893e-05,
      "loss": 0.5106,
      "step": 2150
    },
    {
      "epoch": 0.4652146331148234,
      "grad_norm": 7.869847297668457,
      "learning_rate": 1.8086310893908673e-05,
      "loss": 0.5271,
      "step": 2200
    },
    {
      "epoch": 0.47578769295834217,
      "grad_norm": 5.7856950759887695,
      "learning_rate": 1.8010869537047453e-05,
      "loss": 0.4733,
      "step": 2250
    },
    {
      "epoch": 0.48636075280186086,
      "grad_norm": 7.644218921661377,
      "learning_rate": 1.7935428180186233e-05,
      "loss": 0.5056,
      "step": 2300
    },
    {
      "epoch": 0.49693381264537956,
      "grad_norm": 6.295045375823975,
      "learning_rate": 1.7859986823325017e-05,
      "loss": 0.478,
      "step": 2350
    },
    {
      "epoch": 0.5075068724888983,
      "grad_norm": 5.3759355545043945,
      "learning_rate": 1.7784545466463794e-05,
      "loss": 0.5292,
      "step": 2400
    },
    {
      "epoch": 0.518079932332417,
      "grad_norm": 9.562654495239258,
      "learning_rate": 1.7709104109602578e-05,
      "loss": 0.4766,
      "step": 2450
    },
    {
      "epoch": 0.5286529921759358,
      "grad_norm": 2.059211254119873,
      "learning_rate": 1.7633662752741358e-05,
      "loss": 0.5577,
      "step": 2500
    },
    {
      "epoch": 0.5392260520194544,
      "grad_norm": 3.3371741771698,
      "learning_rate": 1.7558221395880138e-05,
      "loss": 0.4903,
      "step": 2550
    },
    {
      "epoch": 0.5497991118629731,
      "grad_norm": 6.96537446975708,
      "learning_rate": 1.748278003901892e-05,
      "loss": 0.5216,
      "step": 2600
    },
    {
      "epoch": 0.5603721717064919,
      "grad_norm": 12.757112503051758,
      "learning_rate": 1.74073386821577e-05,
      "loss": 0.547,
      "step": 2650
    },
    {
      "epoch": 0.5709452315500105,
      "grad_norm": 7.996160984039307,
      "learning_rate": 1.7331897325296482e-05,
      "loss": 0.5227,
      "step": 2700
    },
    {
      "epoch": 0.5815182913935293,
      "grad_norm": 10.81688117980957,
      "learning_rate": 1.7256455968435263e-05,
      "loss": 0.5246,
      "step": 2750
    },
    {
      "epoch": 0.592091351237048,
      "grad_norm": 5.784497261047363,
      "learning_rate": 1.7181014611574043e-05,
      "loss": 0.5063,
      "step": 2800
    },
    {
      "epoch": 0.6026644110805667,
      "grad_norm": 5.527698040008545,
      "learning_rate": 1.7105573254712823e-05,
      "loss": 0.5079,
      "step": 2850
    },
    {
      "epoch": 0.6132374709240854,
      "grad_norm": 7.221369743347168,
      "learning_rate": 1.7030131897851607e-05,
      "loss": 0.4922,
      "step": 2900
    },
    {
      "epoch": 0.6238105307676042,
      "grad_norm": 4.170981407165527,
      "learning_rate": 1.6954690540990387e-05,
      "loss": 0.4631,
      "step": 2950
    },
    {
      "epoch": 0.6343835906111228,
      "grad_norm": 2.997122287750244,
      "learning_rate": 1.6879249184129167e-05,
      "loss": 0.4891,
      "step": 3000
    },
    {
      "epoch": 0.6449566504546416,
      "grad_norm": 3.317134141921997,
      "learning_rate": 1.6803807827267948e-05,
      "loss": 0.5361,
      "step": 3050
    },
    {
      "epoch": 0.6555297102981603,
      "grad_norm": 9.707466125488281,
      "learning_rate": 1.6728366470406728e-05,
      "loss": 0.4875,
      "step": 3100
    },
    {
      "epoch": 0.666102770141679,
      "grad_norm": 9.83971118927002,
      "learning_rate": 1.6652925113545508e-05,
      "loss": 0.5514,
      "step": 3150
    },
    {
      "epoch": 0.6766758299851977,
      "grad_norm": 9.338716506958008,
      "learning_rate": 1.657748375668429e-05,
      "loss": 0.4895,
      "step": 3200
    },
    {
      "epoch": 0.6872488898287165,
      "grad_norm": 2.9440112113952637,
      "learning_rate": 1.6502042399823072e-05,
      "loss": 0.4823,
      "step": 3250
    },
    {
      "epoch": 0.6978219496722351,
      "grad_norm": 14.791674613952637,
      "learning_rate": 1.6426601042961852e-05,
      "loss": 0.4743,
      "step": 3300
    },
    {
      "epoch": 0.7083950095157538,
      "grad_norm": 3.2558584213256836,
      "learning_rate": 1.6351159686100633e-05,
      "loss": 0.4709,
      "step": 3350
    },
    {
      "epoch": 0.7189680693592726,
      "grad_norm": 6.650009632110596,
      "learning_rate": 1.6275718329239413e-05,
      "loss": 0.4542,
      "step": 3400
    },
    {
      "epoch": 0.7295411292027912,
      "grad_norm": 8.48292350769043,
      "learning_rate": 1.6200276972378196e-05,
      "loss": 0.5402,
      "step": 3450
    },
    {
      "epoch": 0.74011418904631,
      "grad_norm": 7.751077651977539,
      "learning_rate": 1.6124835615516977e-05,
      "loss": 0.4947,
      "step": 3500
    },
    {
      "epoch": 0.7506872488898287,
      "grad_norm": 3.1062896251678467,
      "learning_rate": 1.6049394258655754e-05,
      "loss": 0.4554,
      "step": 3550
    },
    {
      "epoch": 0.7612603087333474,
      "grad_norm": 7.0531415939331055,
      "learning_rate": 1.5973952901794537e-05,
      "loss": 0.5189,
      "step": 3600
    },
    {
      "epoch": 0.7718333685768661,
      "grad_norm": 9.115802764892578,
      "learning_rate": 1.5898511544933318e-05,
      "loss": 0.4151,
      "step": 3650
    },
    {
      "epoch": 0.7824064284203849,
      "grad_norm": 4.491584777832031,
      "learning_rate": 1.5823070188072098e-05,
      "loss": 0.5119,
      "step": 3700
    },
    {
      "epoch": 0.7929794882639035,
      "grad_norm": 18.249792098999023,
      "learning_rate": 1.5747628831210878e-05,
      "loss": 0.4936,
      "step": 3750
    },
    {
      "epoch": 0.8035525481074223,
      "grad_norm": 8.93071460723877,
      "learning_rate": 1.5672187474349662e-05,
      "loss": 0.4496,
      "step": 3800
    },
    {
      "epoch": 0.814125607950941,
      "grad_norm": 11.072824478149414,
      "learning_rate": 1.5596746117488442e-05,
      "loss": 0.4429,
      "step": 3850
    },
    {
      "epoch": 0.8246986677944598,
      "grad_norm": 2.28176212310791,
      "learning_rate": 1.5521304760627222e-05,
      "loss": 0.452,
      "step": 3900
    },
    {
      "epoch": 0.8352717276379784,
      "grad_norm": 0.5334054827690125,
      "learning_rate": 1.5445863403766003e-05,
      "loss": 0.5174,
      "step": 3950
    },
    {
      "epoch": 0.8458447874814972,
      "grad_norm": 10.664823532104492,
      "learning_rate": 1.5370422046904783e-05,
      "loss": 0.4718,
      "step": 4000
    },
    {
      "epoch": 0.8564178473250159,
      "grad_norm": 3.7231082916259766,
      "learning_rate": 1.5294980690043566e-05,
      "loss": 0.4733,
      "step": 4050
    },
    {
      "epoch": 0.8669909071685346,
      "grad_norm": 2.055471420288086,
      "learning_rate": 1.5219539333182345e-05,
      "loss": 0.428,
      "step": 4100
    },
    {
      "epoch": 0.8775639670120533,
      "grad_norm": 9.685327529907227,
      "learning_rate": 1.5144097976321127e-05,
      "loss": 0.4573,
      "step": 4150
    },
    {
      "epoch": 0.888137026855572,
      "grad_norm": 4.0107550621032715,
      "learning_rate": 1.5068656619459907e-05,
      "loss": 0.4712,
      "step": 4200
    },
    {
      "epoch": 0.8987100866990907,
      "grad_norm": 4.092140197753906,
      "learning_rate": 1.499321526259869e-05,
      "loss": 0.4344,
      "step": 4250
    },
    {
      "epoch": 0.9092831465426094,
      "grad_norm": 5.453145980834961,
      "learning_rate": 1.491777390573747e-05,
      "loss": 0.4967,
      "step": 4300
    },
    {
      "epoch": 0.9198562063861282,
      "grad_norm": 6.099764347076416,
      "learning_rate": 1.484233254887625e-05,
      "loss": 0.4773,
      "step": 4350
    },
    {
      "epoch": 0.9304292662296468,
      "grad_norm": 5.3555588722229,
      "learning_rate": 1.4766891192015032e-05,
      "loss": 0.482,
      "step": 4400
    },
    {
      "epoch": 0.9410023260731656,
      "grad_norm": 3.868960380554199,
      "learning_rate": 1.469144983515381e-05,
      "loss": 0.454,
      "step": 4450
    },
    {
      "epoch": 0.9515753859166843,
      "grad_norm": 8.971285820007324,
      "learning_rate": 1.4616008478292594e-05,
      "loss": 0.5162,
      "step": 4500
    },
    {
      "epoch": 0.962148445760203,
      "grad_norm": 7.144505977630615,
      "learning_rate": 1.4540567121431373e-05,
      "loss": 0.412,
      "step": 4550
    },
    {
      "epoch": 0.9727215056037217,
      "grad_norm": 13.30410099029541,
      "learning_rate": 1.4465125764570154e-05,
      "loss": 0.4579,
      "step": 4600
    },
    {
      "epoch": 0.9832945654472405,
      "grad_norm": 3.4991743564605713,
      "learning_rate": 1.4389684407708935e-05,
      "loss": 0.3995,
      "step": 4650
    },
    {
      "epoch": 0.9938676252907591,
      "grad_norm": 12.339458465576172,
      "learning_rate": 1.4314243050847717e-05,
      "loss": 0.4895,
      "step": 4700
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.7979488263903574,
      "eval_f1": 0.7976701658087613,
      "eval_loss": 0.4514825642108917,
      "eval_runtime": 45.5085,
      "eval_samples_per_second": 207.829,
      "eval_steps_per_second": 25.995,
      "step": 4729
    },
    {
      "epoch": 1.0044406851342778,
      "grad_norm": 11.332819938659668,
      "learning_rate": 1.4238801693986497e-05,
      "loss": 0.4082,
      "step": 4750
    },
    {
      "epoch": 1.0150137449777965,
      "grad_norm": 3.20015287399292,
      "learning_rate": 1.4163360337125277e-05,
      "loss": 0.3053,
      "step": 4800
    },
    {
      "epoch": 1.0255868048213153,
      "grad_norm": 11.529474258422852,
      "learning_rate": 1.408791898026406e-05,
      "loss": 0.3887,
      "step": 4850
    },
    {
      "epoch": 1.036159864664834,
      "grad_norm": 9.15365982055664,
      "learning_rate": 1.401247762340284e-05,
      "loss": 0.3608,
      "step": 4900
    },
    {
      "epoch": 1.0467329245083528,
      "grad_norm": 6.521333694458008,
      "learning_rate": 1.3937036266541621e-05,
      "loss": 0.3825,
      "step": 4950
    },
    {
      "epoch": 1.0573059843518715,
      "grad_norm": 11.063582420349121,
      "learning_rate": 1.3861594909680402e-05,
      "loss": 0.3983,
      "step": 5000
    },
    {
      "epoch": 1.06787904419539,
      "grad_norm": 5.61434268951416,
      "learning_rate": 1.3786153552819184e-05,
      "loss": 0.3498,
      "step": 5050
    },
    {
      "epoch": 1.0784521040389088,
      "grad_norm": 4.973913669586182,
      "learning_rate": 1.3710712195957962e-05,
      "loss": 0.3668,
      "step": 5100
    },
    {
      "epoch": 1.0890251638824275,
      "grad_norm": 21.636411666870117,
      "learning_rate": 1.3635270839096746e-05,
      "loss": 0.3535,
      "step": 5150
    },
    {
      "epoch": 1.0995982237259463,
      "grad_norm": 9.988651275634766,
      "learning_rate": 1.3559829482235524e-05,
      "loss": 0.3895,
      "step": 5200
    },
    {
      "epoch": 1.110171283569465,
      "grad_norm": 11.765693664550781,
      "learning_rate": 1.3484388125374305e-05,
      "loss": 0.3898,
      "step": 5250
    },
    {
      "epoch": 1.1207443434129838,
      "grad_norm": 7.365621089935303,
      "learning_rate": 1.3408946768513087e-05,
      "loss": 0.391,
      "step": 5300
    },
    {
      "epoch": 1.1313174032565025,
      "grad_norm": 9.2944974899292,
      "learning_rate": 1.3333505411651867e-05,
      "loss": 0.3753,
      "step": 5350
    },
    {
      "epoch": 1.141890463100021,
      "grad_norm": 6.930461883544922,
      "learning_rate": 1.3258064054790649e-05,
      "loss": 0.3699,
      "step": 5400
    },
    {
      "epoch": 1.1524635229435398,
      "grad_norm": 13.272493362426758,
      "learning_rate": 1.318262269792943e-05,
      "loss": 0.3431,
      "step": 5450
    },
    {
      "epoch": 1.1630365827870586,
      "grad_norm": 3.0938267707824707,
      "learning_rate": 1.3107181341068211e-05,
      "loss": 0.2686,
      "step": 5500
    },
    {
      "epoch": 1.1736096426305773,
      "grad_norm": 5.654418468475342,
      "learning_rate": 1.3031739984206991e-05,
      "loss": 0.3984,
      "step": 5550
    },
    {
      "epoch": 1.184182702474096,
      "grad_norm": 8.964588165283203,
      "learning_rate": 1.2956298627345773e-05,
      "loss": 0.3153,
      "step": 5600
    },
    {
      "epoch": 1.1947557623176146,
      "grad_norm": 9.440595626831055,
      "learning_rate": 1.2880857270484554e-05,
      "loss": 0.3961,
      "step": 5650
    },
    {
      "epoch": 1.2053288221611334,
      "grad_norm": 2.14886212348938,
      "learning_rate": 1.2805415913623332e-05,
      "loss": 0.399,
      "step": 5700
    },
    {
      "epoch": 1.215901882004652,
      "grad_norm": 15.050630569458008,
      "learning_rate": 1.2729974556762116e-05,
      "loss": 0.3332,
      "step": 5750
    },
    {
      "epoch": 1.2264749418481709,
      "grad_norm": 12.321399688720703,
      "learning_rate": 1.2654533199900894e-05,
      "loss": 0.357,
      "step": 5800
    },
    {
      "epoch": 1.2370480016916896,
      "grad_norm": 8.873641014099121,
      "learning_rate": 1.2579091843039676e-05,
      "loss": 0.3658,
      "step": 5850
    },
    {
      "epoch": 1.2476210615352084,
      "grad_norm": 14.641634941101074,
      "learning_rate": 1.2503650486178457e-05,
      "loss": 0.3314,
      "step": 5900
    },
    {
      "epoch": 1.258194121378727,
      "grad_norm": 12.548749923706055,
      "learning_rate": 1.2428209129317239e-05,
      "loss": 0.3399,
      "step": 5950
    },
    {
      "epoch": 1.2687671812222456,
      "grad_norm": 6.017930507659912,
      "learning_rate": 1.2352767772456019e-05,
      "loss": 0.3602,
      "step": 6000
    },
    {
      "epoch": 1.2793402410657644,
      "grad_norm": 40.1791877746582,
      "learning_rate": 1.2277326415594801e-05,
      "loss": 0.3692,
      "step": 6050
    },
    {
      "epoch": 1.2899133009092831,
      "grad_norm": 38.49607467651367,
      "learning_rate": 1.2201885058733581e-05,
      "loss": 0.2877,
      "step": 6100
    },
    {
      "epoch": 1.3004863607528019,
      "grad_norm": 14.93587589263916,
      "learning_rate": 1.2126443701872361e-05,
      "loss": 0.3617,
      "step": 6150
    },
    {
      "epoch": 1.3110594205963206,
      "grad_norm": 5.4458537101745605,
      "learning_rate": 1.2051002345011143e-05,
      "loss": 0.3331,
      "step": 6200
    },
    {
      "epoch": 1.3216324804398392,
      "grad_norm": 34.96612548828125,
      "learning_rate": 1.1975560988149924e-05,
      "loss": 0.3605,
      "step": 6250
    },
    {
      "epoch": 1.3322055402833581,
      "grad_norm": 28.63680648803711,
      "learning_rate": 1.1900119631288706e-05,
      "loss": 0.3381,
      "step": 6300
    },
    {
      "epoch": 1.3427786001268767,
      "grad_norm": 8.905688285827637,
      "learning_rate": 1.1824678274427484e-05,
      "loss": 0.2961,
      "step": 6350
    },
    {
      "epoch": 1.3533516599703954,
      "grad_norm": 14.07498836517334,
      "learning_rate": 1.1749236917566268e-05,
      "loss": 0.3534,
      "step": 6400
    },
    {
      "epoch": 1.3639247198139142,
      "grad_norm": 15.06459903717041,
      "learning_rate": 1.1673795560705046e-05,
      "loss": 0.38,
      "step": 6450
    },
    {
      "epoch": 1.374497779657433,
      "grad_norm": 4.868040084838867,
      "learning_rate": 1.1598354203843827e-05,
      "loss": 0.328,
      "step": 6500
    },
    {
      "epoch": 1.3850708395009517,
      "grad_norm": 13.050298690795898,
      "learning_rate": 1.1522912846982609e-05,
      "loss": 0.3503,
      "step": 6550
    },
    {
      "epoch": 1.3956438993444702,
      "grad_norm": 14.185402870178223,
      "learning_rate": 1.1447471490121389e-05,
      "loss": 0.281,
      "step": 6600
    },
    {
      "epoch": 1.406216959187989,
      "grad_norm": 14.623916625976562,
      "learning_rate": 1.1372030133260171e-05,
      "loss": 0.2846,
      "step": 6650
    },
    {
      "epoch": 1.4167900190315077,
      "grad_norm": 16.512107849121094,
      "learning_rate": 1.1296588776398951e-05,
      "loss": 0.3442,
      "step": 6700
    },
    {
      "epoch": 1.4273630788750264,
      "grad_norm": 8.177905082702637,
      "learning_rate": 1.1221147419537733e-05,
      "loss": 0.312,
      "step": 6750
    },
    {
      "epoch": 1.4379361387185452,
      "grad_norm": 9.697278022766113,
      "learning_rate": 1.1145706062676513e-05,
      "loss": 0.3632,
      "step": 6800
    },
    {
      "epoch": 1.4485091985620637,
      "grad_norm": 24.097536087036133,
      "learning_rate": 1.1070264705815295e-05,
      "loss": 0.3149,
      "step": 6850
    },
    {
      "epoch": 1.4590822584055827,
      "grad_norm": 3.080275297164917,
      "learning_rate": 1.0994823348954076e-05,
      "loss": 0.3165,
      "step": 6900
    },
    {
      "epoch": 1.4696553182491012,
      "grad_norm": 1.215409278869629,
      "learning_rate": 1.0919381992092854e-05,
      "loss": 0.3197,
      "step": 6950
    },
    {
      "epoch": 1.48022837809262,
      "grad_norm": 15.369301795959473,
      "learning_rate": 1.0843940635231636e-05,
      "loss": 0.344,
      "step": 7000
    },
    {
      "epoch": 1.4908014379361387,
      "grad_norm": 11.350268363952637,
      "learning_rate": 1.0768499278370416e-05,
      "loss": 0.4046,
      "step": 7050
    },
    {
      "epoch": 1.5013744977796575,
      "grad_norm": 29.472158432006836,
      "learning_rate": 1.0693057921509198e-05,
      "loss": 0.3679,
      "step": 7100
    },
    {
      "epoch": 1.5119475576231762,
      "grad_norm": 14.808784484863281,
      "learning_rate": 1.0617616564647979e-05,
      "loss": 0.3811,
      "step": 7150
    },
    {
      "epoch": 1.5225206174666948,
      "grad_norm": 17.979473114013672,
      "learning_rate": 1.0542175207786759e-05,
      "loss": 0.3426,
      "step": 7200
    },
    {
      "epoch": 1.5330936773102137,
      "grad_norm": 4.896825790405273,
      "learning_rate": 1.0466733850925541e-05,
      "loss": 0.3155,
      "step": 7250
    },
    {
      "epoch": 1.5436667371537323,
      "grad_norm": 10.3132963180542,
      "learning_rate": 1.0391292494064321e-05,
      "loss": 0.3177,
      "step": 7300
    },
    {
      "epoch": 1.554239796997251,
      "grad_norm": 0.36288687586784363,
      "learning_rate": 1.0315851137203103e-05,
      "loss": 0.2914,
      "step": 7350
    },
    {
      "epoch": 1.5648128568407698,
      "grad_norm": 5.665973663330078,
      "learning_rate": 1.0240409780341883e-05,
      "loss": 0.374,
      "step": 7400
    },
    {
      "epoch": 1.5753859166842883,
      "grad_norm": 27.743349075317383,
      "learning_rate": 1.0164968423480665e-05,
      "loss": 0.3017,
      "step": 7450
    },
    {
      "epoch": 1.5859589765278073,
      "grad_norm": 8.944555282592773,
      "learning_rate": 1.0089527066619446e-05,
      "loss": 0.3191,
      "step": 7500
    },
    {
      "epoch": 1.5965320363713258,
      "grad_norm": 12.416226387023926,
      "learning_rate": 1.0014085709758228e-05,
      "loss": 0.3525,
      "step": 7550
    },
    {
      "epoch": 1.6071050962148445,
      "grad_norm": 2.7698752880096436,
      "learning_rate": 9.938644352897006e-06,
      "loss": 0.2815,
      "step": 7600
    },
    {
      "epoch": 1.6176781560583633,
      "grad_norm": 10.35041618347168,
      "learning_rate": 9.863202996035788e-06,
      "loss": 0.3669,
      "step": 7650
    },
    {
      "epoch": 1.628251215901882,
      "grad_norm": 22.18708038330078,
      "learning_rate": 9.787761639174568e-06,
      "loss": 0.3268,
      "step": 7700
    },
    {
      "epoch": 1.6388242757454008,
      "grad_norm": 11.469756126403809,
      "learning_rate": 9.71232028231335e-06,
      "loss": 0.3281,
      "step": 7750
    },
    {
      "epoch": 1.6493973355889193,
      "grad_norm": 30.72704315185547,
      "learning_rate": 9.63687892545213e-06,
      "loss": 0.3906,
      "step": 7800
    },
    {
      "epoch": 1.6599703954324383,
      "grad_norm": 3.5206563472747803,
      "learning_rate": 9.561437568590911e-06,
      "loss": 0.3334,
      "step": 7850
    },
    {
      "epoch": 1.6705434552759568,
      "grad_norm": 2.4067578315734863,
      "learning_rate": 9.485996211729693e-06,
      "loss": 0.3206,
      "step": 7900
    },
    {
      "epoch": 1.6811165151194756,
      "grad_norm": 2.1780807971954346,
      "learning_rate": 9.410554854868473e-06,
      "loss": 0.3275,
      "step": 7950
    },
    {
      "epoch": 1.6916895749629943,
      "grad_norm": 32.0942497253418,
      "learning_rate": 9.335113498007255e-06,
      "loss": 0.3214,
      "step": 8000
    },
    {
      "epoch": 1.7022626348065129,
      "grad_norm": 13.160368919372559,
      "learning_rate": 9.259672141146035e-06,
      "loss": 0.3368,
      "step": 8050
    },
    {
      "epoch": 1.7128356946500318,
      "grad_norm": 5.7556681632995605,
      "learning_rate": 9.184230784284816e-06,
      "loss": 0.3168,
      "step": 8100
    },
    {
      "epoch": 1.7234087544935504,
      "grad_norm": 0.46439459919929504,
      "learning_rate": 9.108789427423596e-06,
      "loss": 0.2779,
      "step": 8150
    },
    {
      "epoch": 1.733981814337069,
      "grad_norm": 14.79412841796875,
      "learning_rate": 9.033348070562378e-06,
      "loss": 0.3494,
      "step": 8200
    },
    {
      "epoch": 1.7445548741805879,
      "grad_norm": 19.774105072021484,
      "learning_rate": 8.957906713701158e-06,
      "loss": 0.3652,
      "step": 8250
    },
    {
      "epoch": 1.7551279340241066,
      "grad_norm": 3.69887375831604,
      "learning_rate": 8.88246535683994e-06,
      "loss": 0.3212,
      "step": 8300
    },
    {
      "epoch": 1.7657009938676254,
      "grad_norm": 15.437102317810059,
      "learning_rate": 8.80702399997872e-06,
      "loss": 0.274,
      "step": 8350
    },
    {
      "epoch": 1.7762740537111439,
      "grad_norm": 8.711307525634766,
      "learning_rate": 8.731582643117502e-06,
      "loss": 0.3476,
      "step": 8400
    },
    {
      "epoch": 1.7868471135546629,
      "grad_norm": 33.524208068847656,
      "learning_rate": 8.656141286256281e-06,
      "loss": 0.3201,
      "step": 8450
    },
    {
      "epoch": 1.7974201733981814,
      "grad_norm": 1.6866015195846558,
      "learning_rate": 8.580699929395063e-06,
      "loss": 0.2605,
      "step": 8500
    },
    {
      "epoch": 1.8079932332417001,
      "grad_norm": 29.806995391845703,
      "learning_rate": 8.505258572533843e-06,
      "loss": 0.3512,
      "step": 8550
    },
    {
      "epoch": 1.8185662930852189,
      "grad_norm": 8.674875259399414,
      "learning_rate": 8.429817215672625e-06,
      "loss": 0.3449,
      "step": 8600
    },
    {
      "epoch": 1.8291393529287374,
      "grad_norm": 10.03825855255127,
      "learning_rate": 8.354375858811405e-06,
      "loss": 0.3563,
      "step": 8650
    },
    {
      "epoch": 1.8397124127722564,
      "grad_norm": 43.245296478271484,
      "learning_rate": 8.278934501950187e-06,
      "loss": 0.3197,
      "step": 8700
    },
    {
      "epoch": 1.850285472615775,
      "grad_norm": 9.75916862487793,
      "learning_rate": 8.203493145088968e-06,
      "loss": 0.2965,
      "step": 8750
    },
    {
      "epoch": 1.8608585324592937,
      "grad_norm": 1.9368021488189697,
      "learning_rate": 8.128051788227748e-06,
      "loss": 0.3682,
      "step": 8800
    },
    {
      "epoch": 1.8714315923028124,
      "grad_norm": 0.8632673025131226,
      "learning_rate": 8.05261043136653e-06,
      "loss": 0.3256,
      "step": 8850
    },
    {
      "epoch": 1.8820046521463312,
      "grad_norm": 15.74034309387207,
      "learning_rate": 7.97716907450531e-06,
      "loss": 0.3402,
      "step": 8900
    },
    {
      "epoch": 1.89257771198985,
      "grad_norm": 14.778282165527344,
      "learning_rate": 7.90172771764409e-06,
      "loss": 0.2839,
      "step": 8950
    },
    {
      "epoch": 1.9031507718333684,
      "grad_norm": 11.413578987121582,
      "learning_rate": 7.826286360782872e-06,
      "loss": 0.3814,
      "step": 9000
    },
    {
      "epoch": 1.9137238316768874,
      "grad_norm": 5.070478916168213,
      "learning_rate": 7.750845003921653e-06,
      "loss": 0.3132,
      "step": 9050
    },
    {
      "epoch": 1.924296891520406,
      "grad_norm": 4.722480773925781,
      "learning_rate": 7.675403647060433e-06,
      "loss": 0.3397,
      "step": 9100
    },
    {
      "epoch": 1.9348699513639247,
      "grad_norm": 7.033731460571289,
      "learning_rate": 7.599962290199215e-06,
      "loss": 0.2696,
      "step": 9150
    },
    {
      "epoch": 1.9454430112074435,
      "grad_norm": 0.7234598398208618,
      "learning_rate": 7.524520933337996e-06,
      "loss": 0.3145,
      "step": 9200
    },
    {
      "epoch": 1.9560160710509622,
      "grad_norm": 32.051612854003906,
      "learning_rate": 7.449079576476776e-06,
      "loss": 0.2947,
      "step": 9250
    },
    {
      "epoch": 1.966589130894481,
      "grad_norm": 3.6746461391448975,
      "learning_rate": 7.373638219615557e-06,
      "loss": 0.3269,
      "step": 9300
    },
    {
      "epoch": 1.9771621907379995,
      "grad_norm": 0.8911247849464417,
      "learning_rate": 7.298196862754338e-06,
      "loss": 0.3785,
      "step": 9350
    },
    {
      "epoch": 1.9877352505815185,
      "grad_norm": 1.9131745100021362,
      "learning_rate": 7.222755505893119e-06,
      "loss": 0.3136,
      "step": 9400
    },
    {
      "epoch": 1.998308310425037,
      "grad_norm": 34.7707633972168,
      "learning_rate": 7.1473141490319e-06,
      "loss": 0.3432,
      "step": 9450
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8458447874814972,
      "eval_f1": 0.8457687526932212,
      "eval_loss": 0.42247602343559265,
      "eval_runtime": 75.0249,
      "eval_samples_per_second": 126.065,
      "eval_steps_per_second": 15.768,
      "step": 9458
    }
  ],
  "logging_steps": 50,
  "max_steps": 14187,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2503567600899072.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": {
    "learning_rate": 2.1405730595802314e-05,
    "num_train_epochs": 3,
    "per_device_train_batch_size": 8,
    "weight_decay": 0.053536818522940344
  }
}
