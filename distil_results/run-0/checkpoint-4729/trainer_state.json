{
  "best_metric": 0.4514825642108917,
  "best_model_checkpoint": "./distil_results\\run-0\\checkpoint-4729",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 4729,
  "is_hyper_param_search": true,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010573059843518714,
      "grad_norm": 2.4666976928710938,
      "learning_rate": 2.1330289238941094e-05,
      "loss": 0.6779,
      "step": 50
    },
    {
      "epoch": 0.02114611968703743,
      "grad_norm": 3.694483995437622,
      "learning_rate": 2.1254847882079874e-05,
      "loss": 0.675,
      "step": 100
    },
    {
      "epoch": 0.03171917953055614,
      "grad_norm": 6.4158196449279785,
      "learning_rate": 2.1179406525218655e-05,
      "loss": 0.6482,
      "step": 150
    },
    {
      "epoch": 0.04229223937407486,
      "grad_norm": 4.311564922332764,
      "learning_rate": 2.110396516835744e-05,
      "loss": 0.6382,
      "step": 200
    },
    {
      "epoch": 0.05286529921759357,
      "grad_norm": 4.418744087219238,
      "learning_rate": 2.102852381149622e-05,
      "loss": 0.5871,
      "step": 250
    },
    {
      "epoch": 0.06343835906111228,
      "grad_norm": 3.9597091674804688,
      "learning_rate": 2.0953082454635e-05,
      "loss": 0.6027,
      "step": 300
    },
    {
      "epoch": 0.074011418904631,
      "grad_norm": 11.2103271484375,
      "learning_rate": 2.087764109777378e-05,
      "loss": 0.5306,
      "step": 350
    },
    {
      "epoch": 0.08458447874814971,
      "grad_norm": 4.442270278930664,
      "learning_rate": 2.0802199740912563e-05,
      "loss": 0.5737,
      "step": 400
    },
    {
      "epoch": 0.09515753859166842,
      "grad_norm": 3.256399393081665,
      "learning_rate": 2.0726758384051343e-05,
      "loss": 0.6236,
      "step": 450
    },
    {
      "epoch": 0.10573059843518715,
      "grad_norm": 9.64320182800293,
      "learning_rate": 2.065131702719012e-05,
      "loss": 0.6228,
      "step": 500
    },
    {
      "epoch": 0.11630365827870585,
      "grad_norm": 3.2946910858154297,
      "learning_rate": 2.0575875670328904e-05,
      "loss": 0.5914,
      "step": 550
    },
    {
      "epoch": 0.12687671812222456,
      "grad_norm": 11.649035453796387,
      "learning_rate": 2.0500434313467684e-05,
      "loss": 0.574,
      "step": 600
    },
    {
      "epoch": 0.13744977796574329,
      "grad_norm": 5.2252960205078125,
      "learning_rate": 2.0424992956606468e-05,
      "loss": 0.5397,
      "step": 650
    },
    {
      "epoch": 0.148022837809262,
      "grad_norm": 4.026394844055176,
      "learning_rate": 2.0349551599745244e-05,
      "loss": 0.6091,
      "step": 700
    },
    {
      "epoch": 0.1585958976527807,
      "grad_norm": 8.355131149291992,
      "learning_rate": 2.0274110242884028e-05,
      "loss": 0.5782,
      "step": 750
    },
    {
      "epoch": 0.16916895749629943,
      "grad_norm": 3.7679693698883057,
      "learning_rate": 2.019866888602281e-05,
      "loss": 0.5428,
      "step": 800
    },
    {
      "epoch": 0.17974201733981815,
      "grad_norm": 3.9283180236816406,
      "learning_rate": 2.012322752916159e-05,
      "loss": 0.5879,
      "step": 850
    },
    {
      "epoch": 0.19031507718333684,
      "grad_norm": 8.321825981140137,
      "learning_rate": 2.004778617230037e-05,
      "loss": 0.5636,
      "step": 900
    },
    {
      "epoch": 0.20088813702685557,
      "grad_norm": 10.056607246398926,
      "learning_rate": 1.997234481543915e-05,
      "loss": 0.5436,
      "step": 950
    },
    {
      "epoch": 0.2114611968703743,
      "grad_norm": 7.2559733390808105,
      "learning_rate": 1.9896903458577933e-05,
      "loss": 0.5982,
      "step": 1000
    },
    {
      "epoch": 0.222034256713893,
      "grad_norm": 2.738114595413208,
      "learning_rate": 1.9821462101716713e-05,
      "loss": 0.52,
      "step": 1050
    },
    {
      "epoch": 0.2326073165574117,
      "grad_norm": 6.955148220062256,
      "learning_rate": 1.9746020744855493e-05,
      "loss": 0.5378,
      "step": 1100
    },
    {
      "epoch": 0.24318037640093043,
      "grad_norm": 7.953941822052002,
      "learning_rate": 1.9670579387994274e-05,
      "loss": 0.5336,
      "step": 1150
    },
    {
      "epoch": 0.2537534362444491,
      "grad_norm": 7.086467742919922,
      "learning_rate": 1.9595138031133057e-05,
      "loss": 0.5635,
      "step": 1200
    },
    {
      "epoch": 0.2643264960879679,
      "grad_norm": 8.470197677612305,
      "learning_rate": 1.9519696674271834e-05,
      "loss": 0.5527,
      "step": 1250
    },
    {
      "epoch": 0.27489955593148657,
      "grad_norm": 5.725771427154541,
      "learning_rate": 1.9444255317410614e-05,
      "loss": 0.5356,
      "step": 1300
    },
    {
      "epoch": 0.28547261577500527,
      "grad_norm": 7.357840061187744,
      "learning_rate": 1.9368813960549398e-05,
      "loss": 0.5391,
      "step": 1350
    },
    {
      "epoch": 0.296045675618524,
      "grad_norm": 6.478299617767334,
      "learning_rate": 1.929337260368818e-05,
      "loss": 0.5595,
      "step": 1400
    },
    {
      "epoch": 0.3066187354620427,
      "grad_norm": 3.3922934532165527,
      "learning_rate": 1.921793124682696e-05,
      "loss": 0.5732,
      "step": 1450
    },
    {
      "epoch": 0.3171917953055614,
      "grad_norm": 7.2494893074035645,
      "learning_rate": 1.914248988996574e-05,
      "loss": 0.5215,
      "step": 1500
    },
    {
      "epoch": 0.32776485514908016,
      "grad_norm": 6.902097702026367,
      "learning_rate": 1.9067048533104523e-05,
      "loss": 0.5075,
      "step": 1550
    },
    {
      "epoch": 0.33833791499259885,
      "grad_norm": 9.727093696594238,
      "learning_rate": 1.8991607176243303e-05,
      "loss": 0.5202,
      "step": 1600
    },
    {
      "epoch": 0.34891097483611755,
      "grad_norm": 10.47758960723877,
      "learning_rate": 1.8916165819382083e-05,
      "loss": 0.5032,
      "step": 1650
    },
    {
      "epoch": 0.3594840346796363,
      "grad_norm": 8.068986892700195,
      "learning_rate": 1.8840724462520863e-05,
      "loss": 0.5562,
      "step": 1700
    },
    {
      "epoch": 0.370057094523155,
      "grad_norm": 10.651673316955566,
      "learning_rate": 1.8765283105659644e-05,
      "loss": 0.5534,
      "step": 1750
    },
    {
      "epoch": 0.3806301543666737,
      "grad_norm": 6.058019161224365,
      "learning_rate": 1.8689841748798427e-05,
      "loss": 0.5718,
      "step": 1800
    },
    {
      "epoch": 0.39120321421019244,
      "grad_norm": 3.0268146991729736,
      "learning_rate": 1.8614400391937204e-05,
      "loss": 0.5056,
      "step": 1850
    },
    {
      "epoch": 0.40177627405371114,
      "grad_norm": 5.338146209716797,
      "learning_rate": 1.8538959035075988e-05,
      "loss": 0.5381,
      "step": 1900
    },
    {
      "epoch": 0.4123493338972299,
      "grad_norm": 9.605704307556152,
      "learning_rate": 1.8463517678214768e-05,
      "loss": 0.519,
      "step": 1950
    },
    {
      "epoch": 0.4229223937407486,
      "grad_norm": 6.523146152496338,
      "learning_rate": 1.838807632135355e-05,
      "loss": 0.5353,
      "step": 2000
    },
    {
      "epoch": 0.4334954535842673,
      "grad_norm": 3.1398067474365234,
      "learning_rate": 1.831263496449233e-05,
      "loss": 0.5125,
      "step": 2050
    },
    {
      "epoch": 0.444068513427786,
      "grad_norm": 11.838757514953613,
      "learning_rate": 1.8237193607631112e-05,
      "loss": 0.5026,
      "step": 2100
    },
    {
      "epoch": 0.4546415732713047,
      "grad_norm": 8.337739944458008,
      "learning_rate": 1.8161752250769893e-05,
      "loss": 0.5106,
      "step": 2150
    },
    {
      "epoch": 0.4652146331148234,
      "grad_norm": 7.869847297668457,
      "learning_rate": 1.8086310893908673e-05,
      "loss": 0.5271,
      "step": 2200
    },
    {
      "epoch": 0.47578769295834217,
      "grad_norm": 5.7856950759887695,
      "learning_rate": 1.8010869537047453e-05,
      "loss": 0.4733,
      "step": 2250
    },
    {
      "epoch": 0.48636075280186086,
      "grad_norm": 7.644218921661377,
      "learning_rate": 1.7935428180186233e-05,
      "loss": 0.5056,
      "step": 2300
    },
    {
      "epoch": 0.49693381264537956,
      "grad_norm": 6.295045375823975,
      "learning_rate": 1.7859986823325017e-05,
      "loss": 0.478,
      "step": 2350
    },
    {
      "epoch": 0.5075068724888983,
      "grad_norm": 5.3759355545043945,
      "learning_rate": 1.7784545466463794e-05,
      "loss": 0.5292,
      "step": 2400
    },
    {
      "epoch": 0.518079932332417,
      "grad_norm": 9.562654495239258,
      "learning_rate": 1.7709104109602578e-05,
      "loss": 0.4766,
      "step": 2450
    },
    {
      "epoch": 0.5286529921759358,
      "grad_norm": 2.059211254119873,
      "learning_rate": 1.7633662752741358e-05,
      "loss": 0.5577,
      "step": 2500
    },
    {
      "epoch": 0.5392260520194544,
      "grad_norm": 3.3371741771698,
      "learning_rate": 1.7558221395880138e-05,
      "loss": 0.4903,
      "step": 2550
    },
    {
      "epoch": 0.5497991118629731,
      "grad_norm": 6.96537446975708,
      "learning_rate": 1.748278003901892e-05,
      "loss": 0.5216,
      "step": 2600
    },
    {
      "epoch": 0.5603721717064919,
      "grad_norm": 12.757112503051758,
      "learning_rate": 1.74073386821577e-05,
      "loss": 0.547,
      "step": 2650
    },
    {
      "epoch": 0.5709452315500105,
      "grad_norm": 7.996160984039307,
      "learning_rate": 1.7331897325296482e-05,
      "loss": 0.5227,
      "step": 2700
    },
    {
      "epoch": 0.5815182913935293,
      "grad_norm": 10.81688117980957,
      "learning_rate": 1.7256455968435263e-05,
      "loss": 0.5246,
      "step": 2750
    },
    {
      "epoch": 0.592091351237048,
      "grad_norm": 5.784497261047363,
      "learning_rate": 1.7181014611574043e-05,
      "loss": 0.5063,
      "step": 2800
    },
    {
      "epoch": 0.6026644110805667,
      "grad_norm": 5.527698040008545,
      "learning_rate": 1.7105573254712823e-05,
      "loss": 0.5079,
      "step": 2850
    },
    {
      "epoch": 0.6132374709240854,
      "grad_norm": 7.221369743347168,
      "learning_rate": 1.7030131897851607e-05,
      "loss": 0.4922,
      "step": 2900
    },
    {
      "epoch": 0.6238105307676042,
      "grad_norm": 4.170981407165527,
      "learning_rate": 1.6954690540990387e-05,
      "loss": 0.4631,
      "step": 2950
    },
    {
      "epoch": 0.6343835906111228,
      "grad_norm": 2.997122287750244,
      "learning_rate": 1.6879249184129167e-05,
      "loss": 0.4891,
      "step": 3000
    },
    {
      "epoch": 0.6449566504546416,
      "grad_norm": 3.317134141921997,
      "learning_rate": 1.6803807827267948e-05,
      "loss": 0.5361,
      "step": 3050
    },
    {
      "epoch": 0.6555297102981603,
      "grad_norm": 9.707466125488281,
      "learning_rate": 1.6728366470406728e-05,
      "loss": 0.4875,
      "step": 3100
    },
    {
      "epoch": 0.666102770141679,
      "grad_norm": 9.83971118927002,
      "learning_rate": 1.6652925113545508e-05,
      "loss": 0.5514,
      "step": 3150
    },
    {
      "epoch": 0.6766758299851977,
      "grad_norm": 9.338716506958008,
      "learning_rate": 1.657748375668429e-05,
      "loss": 0.4895,
      "step": 3200
    },
    {
      "epoch": 0.6872488898287165,
      "grad_norm": 2.9440112113952637,
      "learning_rate": 1.6502042399823072e-05,
      "loss": 0.4823,
      "step": 3250
    },
    {
      "epoch": 0.6978219496722351,
      "grad_norm": 14.791674613952637,
      "learning_rate": 1.6426601042961852e-05,
      "loss": 0.4743,
      "step": 3300
    },
    {
      "epoch": 0.7083950095157538,
      "grad_norm": 3.2558584213256836,
      "learning_rate": 1.6351159686100633e-05,
      "loss": 0.4709,
      "step": 3350
    },
    {
      "epoch": 0.7189680693592726,
      "grad_norm": 6.650009632110596,
      "learning_rate": 1.6275718329239413e-05,
      "loss": 0.4542,
      "step": 3400
    },
    {
      "epoch": 0.7295411292027912,
      "grad_norm": 8.48292350769043,
      "learning_rate": 1.6200276972378196e-05,
      "loss": 0.5402,
      "step": 3450
    },
    {
      "epoch": 0.74011418904631,
      "grad_norm": 7.751077651977539,
      "learning_rate": 1.6124835615516977e-05,
      "loss": 0.4947,
      "step": 3500
    },
    {
      "epoch": 0.7506872488898287,
      "grad_norm": 3.1062896251678467,
      "learning_rate": 1.6049394258655754e-05,
      "loss": 0.4554,
      "step": 3550
    },
    {
      "epoch": 0.7612603087333474,
      "grad_norm": 7.0531415939331055,
      "learning_rate": 1.5973952901794537e-05,
      "loss": 0.5189,
      "step": 3600
    },
    {
      "epoch": 0.7718333685768661,
      "grad_norm": 9.115802764892578,
      "learning_rate": 1.5898511544933318e-05,
      "loss": 0.4151,
      "step": 3650
    },
    {
      "epoch": 0.7824064284203849,
      "grad_norm": 4.491584777832031,
      "learning_rate": 1.5823070188072098e-05,
      "loss": 0.5119,
      "step": 3700
    },
    {
      "epoch": 0.7929794882639035,
      "grad_norm": 18.249792098999023,
      "learning_rate": 1.5747628831210878e-05,
      "loss": 0.4936,
      "step": 3750
    },
    {
      "epoch": 0.8035525481074223,
      "grad_norm": 8.93071460723877,
      "learning_rate": 1.5672187474349662e-05,
      "loss": 0.4496,
      "step": 3800
    },
    {
      "epoch": 0.814125607950941,
      "grad_norm": 11.072824478149414,
      "learning_rate": 1.5596746117488442e-05,
      "loss": 0.4429,
      "step": 3850
    },
    {
      "epoch": 0.8246986677944598,
      "grad_norm": 2.28176212310791,
      "learning_rate": 1.5521304760627222e-05,
      "loss": 0.452,
      "step": 3900
    },
    {
      "epoch": 0.8352717276379784,
      "grad_norm": 0.5334054827690125,
      "learning_rate": 1.5445863403766003e-05,
      "loss": 0.5174,
      "step": 3950
    },
    {
      "epoch": 0.8458447874814972,
      "grad_norm": 10.664823532104492,
      "learning_rate": 1.5370422046904783e-05,
      "loss": 0.4718,
      "step": 4000
    },
    {
      "epoch": 0.8564178473250159,
      "grad_norm": 3.7231082916259766,
      "learning_rate": 1.5294980690043566e-05,
      "loss": 0.4733,
      "step": 4050
    },
    {
      "epoch": 0.8669909071685346,
      "grad_norm": 2.055471420288086,
      "learning_rate": 1.5219539333182345e-05,
      "loss": 0.428,
      "step": 4100
    },
    {
      "epoch": 0.8775639670120533,
      "grad_norm": 9.685327529907227,
      "learning_rate": 1.5144097976321127e-05,
      "loss": 0.4573,
      "step": 4150
    },
    {
      "epoch": 0.888137026855572,
      "grad_norm": 4.0107550621032715,
      "learning_rate": 1.5068656619459907e-05,
      "loss": 0.4712,
      "step": 4200
    },
    {
      "epoch": 0.8987100866990907,
      "grad_norm": 4.092140197753906,
      "learning_rate": 1.499321526259869e-05,
      "loss": 0.4344,
      "step": 4250
    },
    {
      "epoch": 0.9092831465426094,
      "grad_norm": 5.453145980834961,
      "learning_rate": 1.491777390573747e-05,
      "loss": 0.4967,
      "step": 4300
    },
    {
      "epoch": 0.9198562063861282,
      "grad_norm": 6.099764347076416,
      "learning_rate": 1.484233254887625e-05,
      "loss": 0.4773,
      "step": 4350
    },
    {
      "epoch": 0.9304292662296468,
      "grad_norm": 5.3555588722229,
      "learning_rate": 1.4766891192015032e-05,
      "loss": 0.482,
      "step": 4400
    },
    {
      "epoch": 0.9410023260731656,
      "grad_norm": 3.868960380554199,
      "learning_rate": 1.469144983515381e-05,
      "loss": 0.454,
      "step": 4450
    },
    {
      "epoch": 0.9515753859166843,
      "grad_norm": 8.971285820007324,
      "learning_rate": 1.4616008478292594e-05,
      "loss": 0.5162,
      "step": 4500
    },
    {
      "epoch": 0.962148445760203,
      "grad_norm": 7.144505977630615,
      "learning_rate": 1.4540567121431373e-05,
      "loss": 0.412,
      "step": 4550
    },
    {
      "epoch": 0.9727215056037217,
      "grad_norm": 13.30410099029541,
      "learning_rate": 1.4465125764570154e-05,
      "loss": 0.4579,
      "step": 4600
    },
    {
      "epoch": 0.9832945654472405,
      "grad_norm": 3.4991743564605713,
      "learning_rate": 1.4389684407708935e-05,
      "loss": 0.3995,
      "step": 4650
    },
    {
      "epoch": 0.9938676252907591,
      "grad_norm": 12.339458465576172,
      "learning_rate": 1.4314243050847717e-05,
      "loss": 0.4895,
      "step": 4700
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.7979488263903574,
      "eval_f1": 0.7976701658087613,
      "eval_loss": 0.4514825642108917,
      "eval_runtime": 45.5085,
      "eval_samples_per_second": 207.829,
      "eval_steps_per_second": 25.995,
      "step": 4729
    }
  ],
  "logging_steps": 50,
  "max_steps": 14187,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1245193547366400.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": {
    "learning_rate": 2.1405730595802314e-05,
    "num_train_epochs": 3,
    "per_device_train_batch_size": 8,
    "weight_decay": 0.053536818522940344
  }
}
