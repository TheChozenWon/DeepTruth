{
  "best_metric": 0.3674292266368866,
  "best_model_checkpoint": "./distil_results\\run-10\\checkpoint-4730",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 11825,
  "is_hyper_param_search": true,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.021141649048625793,
      "grad_norm": 2.1176414489746094,
      "learning_rate": 4.743699397994653e-05,
      "loss": 0.6782,
      "step": 50
    },
    {
      "epoch": 0.042283298097251586,
      "grad_norm": 3.0181519985198975,
      "learning_rate": 4.723556300763254e-05,
      "loss": 0.6542,
      "step": 100
    },
    {
      "epoch": 0.06342494714587738,
      "grad_norm": 3.787881851196289,
      "learning_rate": 4.703413203531854e-05,
      "loss": 0.6003,
      "step": 150
    },
    {
      "epoch": 0.08456659619450317,
      "grad_norm": 2.626145839691162,
      "learning_rate": 4.6832701063004546e-05,
      "loss": 0.5568,
      "step": 200
    },
    {
      "epoch": 0.10570824524312897,
      "grad_norm": 5.121377468109131,
      "learning_rate": 4.6631270090690544e-05,
      "loss": 0.6193,
      "step": 250
    },
    {
      "epoch": 0.12684989429175475,
      "grad_norm": 3.718062162399292,
      "learning_rate": 4.642983911837655e-05,
      "loss": 0.5806,
      "step": 300
    },
    {
      "epoch": 0.14799154334038056,
      "grad_norm": 3.0227348804473877,
      "learning_rate": 4.6228408146062546e-05,
      "loss": 0.5627,
      "step": 350
    },
    {
      "epoch": 0.16913319238900634,
      "grad_norm": 2.1395137310028076,
      "learning_rate": 4.602697717374855e-05,
      "loss": 0.5793,
      "step": 400
    },
    {
      "epoch": 0.19027484143763213,
      "grad_norm": 3.483649969100952,
      "learning_rate": 4.5825546201434555e-05,
      "loss": 0.5771,
      "step": 450
    },
    {
      "epoch": 0.21141649048625794,
      "grad_norm": 4.362490653991699,
      "learning_rate": 4.562411522912055e-05,
      "loss": 0.5796,
      "step": 500
    },
    {
      "epoch": 0.23255813953488372,
      "grad_norm": 4.9103498458862305,
      "learning_rate": 4.542268425680656e-05,
      "loss": 0.526,
      "step": 550
    },
    {
      "epoch": 0.2536997885835095,
      "grad_norm": 3.7611310482025146,
      "learning_rate": 4.5221253284492554e-05,
      "loss": 0.5403,
      "step": 600
    },
    {
      "epoch": 0.2748414376321353,
      "grad_norm": 3.6417675018310547,
      "learning_rate": 4.5019822312178566e-05,
      "loss": 0.5426,
      "step": 650
    },
    {
      "epoch": 0.2959830866807611,
      "grad_norm": 3.4896414279937744,
      "learning_rate": 4.481839133986456e-05,
      "loss": 0.5252,
      "step": 700
    },
    {
      "epoch": 0.3171247357293869,
      "grad_norm": 3.550278902053833,
      "learning_rate": 4.461696036755056e-05,
      "loss": 0.5487,
      "step": 750
    },
    {
      "epoch": 0.3382663847780127,
      "grad_norm": 4.863516330718994,
      "learning_rate": 4.4415529395236566e-05,
      "loss": 0.4948,
      "step": 800
    },
    {
      "epoch": 0.3594080338266385,
      "grad_norm": 3.0128333568573,
      "learning_rate": 4.421409842292256e-05,
      "loss": 0.5189,
      "step": 850
    },
    {
      "epoch": 0.38054968287526425,
      "grad_norm": 4.263738632202148,
      "learning_rate": 4.4012667450608574e-05,
      "loss": 0.5434,
      "step": 900
    },
    {
      "epoch": 0.40169133192389006,
      "grad_norm": 2.4861981868743896,
      "learning_rate": 4.381123647829457e-05,
      "loss": 0.5319,
      "step": 950
    },
    {
      "epoch": 0.42283298097251587,
      "grad_norm": 3.3313286304473877,
      "learning_rate": 4.3609805505980577e-05,
      "loss": 0.5221,
      "step": 1000
    },
    {
      "epoch": 0.4439746300211416,
      "grad_norm": 4.72861909866333,
      "learning_rate": 4.3408374533666574e-05,
      "loss": 0.5074,
      "step": 1050
    },
    {
      "epoch": 0.46511627906976744,
      "grad_norm": 4.923120021820068,
      "learning_rate": 4.320694356135258e-05,
      "loss": 0.5096,
      "step": 1100
    },
    {
      "epoch": 0.48625792811839325,
      "grad_norm": 4.773021697998047,
      "learning_rate": 4.300551258903858e-05,
      "loss": 0.4953,
      "step": 1150
    },
    {
      "epoch": 0.507399577167019,
      "grad_norm": 3.640928268432617,
      "learning_rate": 4.280408161672458e-05,
      "loss": 0.4813,
      "step": 1200
    },
    {
      "epoch": 0.5285412262156448,
      "grad_norm": 2.2630081176757812,
      "learning_rate": 4.2602650644410585e-05,
      "loss": 0.5028,
      "step": 1250
    },
    {
      "epoch": 0.5496828752642706,
      "grad_norm": 3.488926887512207,
      "learning_rate": 4.240121967209658e-05,
      "loss": 0.4924,
      "step": 1300
    },
    {
      "epoch": 0.5708245243128964,
      "grad_norm": 8.812150955200195,
      "learning_rate": 4.219978869978259e-05,
      "loss": 0.4912,
      "step": 1350
    },
    {
      "epoch": 0.5919661733615222,
      "grad_norm": 4.7808427810668945,
      "learning_rate": 4.199835772746859e-05,
      "loss": 0.4965,
      "step": 1400
    },
    {
      "epoch": 0.6131078224101479,
      "grad_norm": 4.303544998168945,
      "learning_rate": 4.1796926755154596e-05,
      "loss": 0.4807,
      "step": 1450
    },
    {
      "epoch": 0.6342494714587738,
      "grad_norm": 3.0797295570373535,
      "learning_rate": 4.1595495782840594e-05,
      "loss": 0.4658,
      "step": 1500
    },
    {
      "epoch": 0.6553911205073996,
      "grad_norm": 2.6980903148651123,
      "learning_rate": 4.139406481052659e-05,
      "loss": 0.5076,
      "step": 1550
    },
    {
      "epoch": 0.6765327695560254,
      "grad_norm": 3.4878735542297363,
      "learning_rate": 4.1192633838212596e-05,
      "loss": 0.4861,
      "step": 1600
    },
    {
      "epoch": 0.6976744186046512,
      "grad_norm": 3.6549031734466553,
      "learning_rate": 4.09912028658986e-05,
      "loss": 0.4655,
      "step": 1650
    },
    {
      "epoch": 0.718816067653277,
      "grad_norm": 3.2304303646087646,
      "learning_rate": 4.0789771893584605e-05,
      "loss": 0.453,
      "step": 1700
    },
    {
      "epoch": 0.7399577167019028,
      "grad_norm": 3.825324058532715,
      "learning_rate": 4.05883409212706e-05,
      "loss": 0.4954,
      "step": 1750
    },
    {
      "epoch": 0.7610993657505285,
      "grad_norm": 2.175403594970703,
      "learning_rate": 4.038690994895661e-05,
      "loss": 0.4714,
      "step": 1800
    },
    {
      "epoch": 0.7822410147991543,
      "grad_norm": 3.0284361839294434,
      "learning_rate": 4.0185478976642605e-05,
      "loss": 0.4448,
      "step": 1850
    },
    {
      "epoch": 0.8033826638477801,
      "grad_norm": 4.970080852508545,
      "learning_rate": 3.998404800432861e-05,
      "loss": 0.4663,
      "step": 1900
    },
    {
      "epoch": 0.8245243128964059,
      "grad_norm": 5.603749752044678,
      "learning_rate": 3.9782617032014614e-05,
      "loss": 0.4288,
      "step": 1950
    },
    {
      "epoch": 0.8456659619450317,
      "grad_norm": 3.9671108722686768,
      "learning_rate": 3.958118605970061e-05,
      "loss": 0.4615,
      "step": 2000
    },
    {
      "epoch": 0.8668076109936576,
      "grad_norm": 5.852086544036865,
      "learning_rate": 3.9379755087386616e-05,
      "loss": 0.4377,
      "step": 2050
    },
    {
      "epoch": 0.8879492600422833,
      "grad_norm": 3.083298444747925,
      "learning_rate": 3.9178324115072614e-05,
      "loss": 0.4705,
      "step": 2100
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 4.391997337341309,
      "learning_rate": 3.8976893142758625e-05,
      "loss": 0.4416,
      "step": 2150
    },
    {
      "epoch": 0.9302325581395349,
      "grad_norm": 8.608437538146973,
      "learning_rate": 3.877546217044462e-05,
      "loss": 0.4681,
      "step": 2200
    },
    {
      "epoch": 0.9513742071881607,
      "grad_norm": 1.9580260515213013,
      "learning_rate": 3.857403119813062e-05,
      "loss": 0.4403,
      "step": 2250
    },
    {
      "epoch": 0.9725158562367865,
      "grad_norm": 10.662217140197754,
      "learning_rate": 3.8372600225816625e-05,
      "loss": 0.4154,
      "step": 2300
    },
    {
      "epoch": 0.9936575052854123,
      "grad_norm": 7.0779547691345215,
      "learning_rate": 3.817116925350262e-05,
      "loss": 0.4077,
      "step": 2350
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.7930852188623387,
      "eval_f1": 0.7921951196400905,
      "eval_loss": 0.4444333016872406,
      "eval_runtime": 81.3114,
      "eval_samples_per_second": 116.318,
      "eval_steps_per_second": 14.549,
      "step": 2365
    },
    {
      "epoch": 1.014799154334038,
      "grad_norm": 2.96028995513916,
      "learning_rate": 3.7969738281188634e-05,
      "loss": 0.3385,
      "step": 2400
    },
    {
      "epoch": 1.0359408033826638,
      "grad_norm": 7.127109050750732,
      "learning_rate": 3.776830730887463e-05,
      "loss": 0.2929,
      "step": 2450
    },
    {
      "epoch": 1.0570824524312896,
      "grad_norm": 7.255259037017822,
      "learning_rate": 3.7566876336560636e-05,
      "loss": 0.3533,
      "step": 2500
    },
    {
      "epoch": 1.0782241014799154,
      "grad_norm": 8.749979972839355,
      "learning_rate": 3.7365445364246634e-05,
      "loss": 0.2925,
      "step": 2550
    },
    {
      "epoch": 1.0993657505285412,
      "grad_norm": 2.423292398452759,
      "learning_rate": 3.716401439193264e-05,
      "loss": 0.3484,
      "step": 2600
    },
    {
      "epoch": 1.120507399577167,
      "grad_norm": 1.465755581855774,
      "learning_rate": 3.696258341961864e-05,
      "loss": 0.3405,
      "step": 2650
    },
    {
      "epoch": 1.1416490486257929,
      "grad_norm": 7.497413158416748,
      "learning_rate": 3.676115244730464e-05,
      "loss": 0.3469,
      "step": 2700
    },
    {
      "epoch": 1.1627906976744187,
      "grad_norm": 10.629076957702637,
      "learning_rate": 3.6559721474990645e-05,
      "loss": 0.2846,
      "step": 2750
    },
    {
      "epoch": 1.1839323467230445,
      "grad_norm": 7.6076340675354,
      "learning_rate": 3.635829050267664e-05,
      "loss": 0.2989,
      "step": 2800
    },
    {
      "epoch": 1.20507399577167,
      "grad_norm": 13.97437572479248,
      "learning_rate": 3.615685953036265e-05,
      "loss": 0.3273,
      "step": 2850
    },
    {
      "epoch": 1.226215644820296,
      "grad_norm": 7.407544136047363,
      "learning_rate": 3.595542855804865e-05,
      "loss": 0.3022,
      "step": 2900
    },
    {
      "epoch": 1.2473572938689217,
      "grad_norm": 7.913640975952148,
      "learning_rate": 3.575399758573465e-05,
      "loss": 0.3006,
      "step": 2950
    },
    {
      "epoch": 1.2684989429175475,
      "grad_norm": 11.985146522521973,
      "learning_rate": 3.555256661342065e-05,
      "loss": 0.2841,
      "step": 3000
    },
    {
      "epoch": 1.2896405919661733,
      "grad_norm": 2.2689177989959717,
      "learning_rate": 3.535113564110665e-05,
      "loss": 0.3097,
      "step": 3050
    },
    {
      "epoch": 1.3107822410147991,
      "grad_norm": 16.17386245727539,
      "learning_rate": 3.5149704668792655e-05,
      "loss": 0.2899,
      "step": 3100
    },
    {
      "epoch": 1.331923890063425,
      "grad_norm": 2.880948305130005,
      "learning_rate": 3.494827369647866e-05,
      "loss": 0.2896,
      "step": 3150
    },
    {
      "epoch": 1.3530655391120507,
      "grad_norm": 1.8978863954544067,
      "learning_rate": 3.4746842724164664e-05,
      "loss": 0.3033,
      "step": 3200
    },
    {
      "epoch": 1.3742071881606766,
      "grad_norm": 6.438104629516602,
      "learning_rate": 3.454541175185066e-05,
      "loss": 0.3194,
      "step": 3250
    },
    {
      "epoch": 1.3953488372093024,
      "grad_norm": 8.883932113647461,
      "learning_rate": 3.434398077953666e-05,
      "loss": 0.2612,
      "step": 3300
    },
    {
      "epoch": 1.4164904862579282,
      "grad_norm": 6.188982009887695,
      "learning_rate": 3.4142549807222664e-05,
      "loss": 0.2927,
      "step": 3350
    },
    {
      "epoch": 1.437632135306554,
      "grad_norm": 11.881843566894531,
      "learning_rate": 3.394111883490867e-05,
      "loss": 0.3107,
      "step": 3400
    },
    {
      "epoch": 1.4587737843551798,
      "grad_norm": 5.075872421264648,
      "learning_rate": 3.373968786259467e-05,
      "loss": 0.295,
      "step": 3450
    },
    {
      "epoch": 1.4799154334038054,
      "grad_norm": 7.2464470863342285,
      "learning_rate": 3.353825689028067e-05,
      "loss": 0.2988,
      "step": 3500
    },
    {
      "epoch": 1.5010570824524314,
      "grad_norm": 5.083919525146484,
      "learning_rate": 3.3336825917966675e-05,
      "loss": 0.3086,
      "step": 3550
    },
    {
      "epoch": 1.522198731501057,
      "grad_norm": 3.860264301300049,
      "learning_rate": 3.313539494565267e-05,
      "loss": 0.3135,
      "step": 3600
    },
    {
      "epoch": 1.543340380549683,
      "grad_norm": 11.748373985290527,
      "learning_rate": 3.293396397333868e-05,
      "loss": 0.3138,
      "step": 3650
    },
    {
      "epoch": 1.5644820295983086,
      "grad_norm": 6.105813503265381,
      "learning_rate": 3.273253300102468e-05,
      "loss": 0.2787,
      "step": 3700
    },
    {
      "epoch": 1.5856236786469344,
      "grad_norm": 17.420364379882812,
      "learning_rate": 3.253110202871068e-05,
      "loss": 0.2552,
      "step": 3750
    },
    {
      "epoch": 1.6067653276955602,
      "grad_norm": 3.9062843322753906,
      "learning_rate": 3.2329671056396684e-05,
      "loss": 0.2892,
      "step": 3800
    },
    {
      "epoch": 1.627906976744186,
      "grad_norm": 8.404233932495117,
      "learning_rate": 3.212824008408269e-05,
      "loss": 0.3136,
      "step": 3850
    },
    {
      "epoch": 1.6490486257928119,
      "grad_norm": 8.115452766418457,
      "learning_rate": 3.192680911176869e-05,
      "loss": 0.2753,
      "step": 3900
    },
    {
      "epoch": 1.6701902748414377,
      "grad_norm": 7.654045581817627,
      "learning_rate": 3.172537813945469e-05,
      "loss": 0.2966,
      "step": 3950
    },
    {
      "epoch": 1.6913319238900635,
      "grad_norm": 7.17773962020874,
      "learning_rate": 3.1523947167140695e-05,
      "loss": 0.2833,
      "step": 4000
    },
    {
      "epoch": 1.712473572938689,
      "grad_norm": 8.083842277526855,
      "learning_rate": 3.132251619482669e-05,
      "loss": 0.2768,
      "step": 4050
    },
    {
      "epoch": 1.733615221987315,
      "grad_norm": 7.527310371398926,
      "learning_rate": 3.11210852225127e-05,
      "loss": 0.2704,
      "step": 4100
    },
    {
      "epoch": 1.7547568710359407,
      "grad_norm": 8.827425003051758,
      "learning_rate": 3.09196542501987e-05,
      "loss": 0.2977,
      "step": 4150
    },
    {
      "epoch": 1.7758985200845667,
      "grad_norm": 1.333686113357544,
      "learning_rate": 3.07182232778847e-05,
      "loss": 0.2465,
      "step": 4200
    },
    {
      "epoch": 1.7970401691331923,
      "grad_norm": 6.517786979675293,
      "learning_rate": 3.0516792305570704e-05,
      "loss": 0.2485,
      "step": 4250
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 13.165407180786133,
      "learning_rate": 3.0315361333256705e-05,
      "loss": 0.2784,
      "step": 4300
    },
    {
      "epoch": 1.839323467230444,
      "grad_norm": 10.39423942565918,
      "learning_rate": 3.011393036094271e-05,
      "loss": 0.2617,
      "step": 4350
    },
    {
      "epoch": 1.8604651162790697,
      "grad_norm": 16.235774993896484,
      "learning_rate": 2.9912499388628707e-05,
      "loss": 0.2832,
      "step": 4400
    },
    {
      "epoch": 1.8816067653276956,
      "grad_norm": 13.175912857055664,
      "learning_rate": 2.9711068416314708e-05,
      "loss": 0.245,
      "step": 4450
    },
    {
      "epoch": 1.9027484143763214,
      "grad_norm": 7.450299263000488,
      "learning_rate": 2.9509637444000713e-05,
      "loss": 0.2702,
      "step": 4500
    },
    {
      "epoch": 1.9238900634249472,
      "grad_norm": 13.46331787109375,
      "learning_rate": 2.9308206471686714e-05,
      "loss": 0.2818,
      "step": 4550
    },
    {
      "epoch": 1.945031712473573,
      "grad_norm": 4.490875720977783,
      "learning_rate": 2.9106775499372718e-05,
      "loss": 0.2664,
      "step": 4600
    },
    {
      "epoch": 1.9661733615221988,
      "grad_norm": 7.527230262756348,
      "learning_rate": 2.8905344527058716e-05,
      "loss": 0.2883,
      "step": 4650
    },
    {
      "epoch": 1.9873150105708244,
      "grad_norm": 6.1011786460876465,
      "learning_rate": 2.8703913554744724e-05,
      "loss": 0.2672,
      "step": 4700
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8612814548530344,
      "eval_f1": 0.8612355629092714,
      "eval_loss": 0.3674292266368866,
      "eval_runtime": 79.0162,
      "eval_samples_per_second": 119.697,
      "eval_steps_per_second": 14.972,
      "step": 4730
    },
    {
      "epoch": 2.0084566596194504,
      "grad_norm": 3.761263132095337,
      "learning_rate": 2.850248258243072e-05,
      "loss": 0.1905,
      "step": 4750
    },
    {
      "epoch": 2.029598308668076,
      "grad_norm": 10.05385684967041,
      "learning_rate": 2.8301051610116722e-05,
      "loss": 0.1596,
      "step": 4800
    },
    {
      "epoch": 2.050739957716702,
      "grad_norm": 27.48297691345215,
      "learning_rate": 2.8099620637802727e-05,
      "loss": 0.1583,
      "step": 4850
    },
    {
      "epoch": 2.0718816067653276,
      "grad_norm": 1.933630347251892,
      "learning_rate": 2.7898189665488725e-05,
      "loss": 0.1713,
      "step": 4900
    },
    {
      "epoch": 2.0930232558139537,
      "grad_norm": 16.747943878173828,
      "learning_rate": 2.7696758693174732e-05,
      "loss": 0.1334,
      "step": 4950
    },
    {
      "epoch": 2.1141649048625792,
      "grad_norm": 8.880537986755371,
      "learning_rate": 2.749532772086073e-05,
      "loss": 0.122,
      "step": 5000
    },
    {
      "epoch": 2.1353065539112053,
      "grad_norm": 23.553150177001953,
      "learning_rate": 2.7293896748546735e-05,
      "loss": 0.1345,
      "step": 5050
    },
    {
      "epoch": 2.156448202959831,
      "grad_norm": 13.2627592086792,
      "learning_rate": 2.7092465776232736e-05,
      "loss": 0.1534,
      "step": 5100
    },
    {
      "epoch": 2.177589852008457,
      "grad_norm": 0.23267048597335815,
      "learning_rate": 2.6891034803918737e-05,
      "loss": 0.147,
      "step": 5150
    },
    {
      "epoch": 2.1987315010570825,
      "grad_norm": 5.019896984100342,
      "learning_rate": 2.668960383160474e-05,
      "loss": 0.1849,
      "step": 5200
    },
    {
      "epoch": 2.219873150105708,
      "grad_norm": 6.9013824462890625,
      "learning_rate": 2.648817285929074e-05,
      "loss": 0.1668,
      "step": 5250
    },
    {
      "epoch": 2.241014799154334,
      "grad_norm": 23.625507354736328,
      "learning_rate": 2.6286741886976743e-05,
      "loss": 0.1386,
      "step": 5300
    },
    {
      "epoch": 2.2621564482029597,
      "grad_norm": 3.5750644207000732,
      "learning_rate": 2.6085310914662744e-05,
      "loss": 0.1349,
      "step": 5350
    },
    {
      "epoch": 2.2832980972515857,
      "grad_norm": 0.27984175086021423,
      "learning_rate": 2.588387994234875e-05,
      "loss": 0.1293,
      "step": 5400
    },
    {
      "epoch": 2.3044397463002113,
      "grad_norm": 0.08604040741920471,
      "learning_rate": 2.568244897003475e-05,
      "loss": 0.1449,
      "step": 5450
    },
    {
      "epoch": 2.3255813953488373,
      "grad_norm": 12.99696159362793,
      "learning_rate": 2.5481017997720748e-05,
      "loss": 0.2122,
      "step": 5500
    },
    {
      "epoch": 2.346723044397463,
      "grad_norm": 0.36094269156455994,
      "learning_rate": 2.5279587025406755e-05,
      "loss": 0.0989,
      "step": 5550
    },
    {
      "epoch": 2.367864693446089,
      "grad_norm": 0.8124027848243713,
      "learning_rate": 2.5078156053092753e-05,
      "loss": 0.1701,
      "step": 5600
    },
    {
      "epoch": 2.3890063424947146,
      "grad_norm": 19.504331588745117,
      "learning_rate": 2.4876725080778758e-05,
      "loss": 0.2091,
      "step": 5650
    },
    {
      "epoch": 2.41014799154334,
      "grad_norm": 0.11362044513225555,
      "learning_rate": 2.467529410846476e-05,
      "loss": 0.1331,
      "step": 5700
    },
    {
      "epoch": 2.431289640591966,
      "grad_norm": 1.2906326055526733,
      "learning_rate": 2.4473863136150763e-05,
      "loss": 0.1369,
      "step": 5750
    },
    {
      "epoch": 2.452431289640592,
      "grad_norm": 4.350234031677246,
      "learning_rate": 2.4272432163836764e-05,
      "loss": 0.13,
      "step": 5800
    },
    {
      "epoch": 2.473572938689218,
      "grad_norm": 0.4289300739765167,
      "learning_rate": 2.4071001191522762e-05,
      "loss": 0.1718,
      "step": 5850
    },
    {
      "epoch": 2.4947145877378434,
      "grad_norm": 15.896223068237305,
      "learning_rate": 2.3869570219208766e-05,
      "loss": 0.1625,
      "step": 5900
    },
    {
      "epoch": 2.5158562367864694,
      "grad_norm": 1.9686229228973389,
      "learning_rate": 2.366813924689477e-05,
      "loss": 0.1434,
      "step": 5950
    },
    {
      "epoch": 2.536997885835095,
      "grad_norm": 9.432112693786621,
      "learning_rate": 2.3466708274580772e-05,
      "loss": 0.0938,
      "step": 6000
    },
    {
      "epoch": 2.558139534883721,
      "grad_norm": 17.208114624023438,
      "learning_rate": 2.3265277302266773e-05,
      "loss": 0.1755,
      "step": 6050
    },
    {
      "epoch": 2.5792811839323466,
      "grad_norm": 7.0469584465026855,
      "learning_rate": 2.3063846329952774e-05,
      "loss": 0.1671,
      "step": 6100
    },
    {
      "epoch": 2.6004228329809727,
      "grad_norm": 6.691427707672119,
      "learning_rate": 2.2862415357638775e-05,
      "loss": 0.1552,
      "step": 6150
    },
    {
      "epoch": 2.6215644820295982,
      "grad_norm": 0.2829618453979492,
      "learning_rate": 2.266098438532478e-05,
      "loss": 0.129,
      "step": 6200
    },
    {
      "epoch": 2.6427061310782243,
      "grad_norm": 0.5472341775894165,
      "learning_rate": 2.245955341301078e-05,
      "loss": 0.1597,
      "step": 6250
    },
    {
      "epoch": 2.66384778012685,
      "grad_norm": 5.825351715087891,
      "learning_rate": 2.2258122440696785e-05,
      "loss": 0.1603,
      "step": 6300
    },
    {
      "epoch": 2.6849894291754755,
      "grad_norm": 13.08242416381836,
      "learning_rate": 2.2056691468382786e-05,
      "loss": 0.1583,
      "step": 6350
    },
    {
      "epoch": 2.7061310782241015,
      "grad_norm": 0.3803778290748596,
      "learning_rate": 2.1855260496068787e-05,
      "loss": 0.1095,
      "step": 6400
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 5.1040544509887695,
      "learning_rate": 2.1653829523754788e-05,
      "loss": 0.1856,
      "step": 6450
    },
    {
      "epoch": 2.748414376321353,
      "grad_norm": 7.839865207672119,
      "learning_rate": 2.145239855144079e-05,
      "loss": 0.1684,
      "step": 6500
    },
    {
      "epoch": 2.7695560253699787,
      "grad_norm": 8.564057350158691,
      "learning_rate": 2.1250967579126794e-05,
      "loss": 0.1166,
      "step": 6550
    },
    {
      "epoch": 2.7906976744186047,
      "grad_norm": 7.555939674377441,
      "learning_rate": 2.1049536606812795e-05,
      "loss": 0.1461,
      "step": 6600
    },
    {
      "epoch": 2.8118393234672303,
      "grad_norm": 6.192167282104492,
      "learning_rate": 2.0848105634498796e-05,
      "loss": 0.1548,
      "step": 6650
    },
    {
      "epoch": 2.8329809725158563,
      "grad_norm": 6.004049777984619,
      "learning_rate": 2.06466746621848e-05,
      "loss": 0.1208,
      "step": 6700
    },
    {
      "epoch": 2.854122621564482,
      "grad_norm": 0.16165462136268616,
      "learning_rate": 2.0445243689870798e-05,
      "loss": 0.1071,
      "step": 6750
    },
    {
      "epoch": 2.875264270613108,
      "grad_norm": 0.09257776290178299,
      "learning_rate": 2.0243812717556803e-05,
      "loss": 0.109,
      "step": 6800
    },
    {
      "epoch": 2.8964059196617336,
      "grad_norm": 15.91187572479248,
      "learning_rate": 2.0042381745242804e-05,
      "loss": 0.1764,
      "step": 6850
    },
    {
      "epoch": 2.9175475687103596,
      "grad_norm": 2.192274808883667,
      "learning_rate": 1.9840950772928805e-05,
      "loss": 0.1564,
      "step": 6900
    },
    {
      "epoch": 2.938689217758985,
      "grad_norm": 29.966575622558594,
      "learning_rate": 1.963951980061481e-05,
      "loss": 0.1416,
      "step": 6950
    },
    {
      "epoch": 2.9598308668076108,
      "grad_norm": 17.332231521606445,
      "learning_rate": 1.943808882830081e-05,
      "loss": 0.1367,
      "step": 7000
    },
    {
      "epoch": 2.980972515856237,
      "grad_norm": 29.808324813842773,
      "learning_rate": 1.9236657855986815e-05,
      "loss": 0.1696,
      "step": 7050
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8694227109325439,
      "eval_f1": 0.8692014506254886,
      "eval_loss": 0.594417929649353,
      "eval_runtime": 77.1071,
      "eval_samples_per_second": 122.661,
      "eval_steps_per_second": 15.342,
      "step": 7095
    },
    {
      "epoch": 3.0021141649048624,
      "grad_norm": 0.02106783725321293,
      "learning_rate": 1.9035226883672812e-05,
      "loss": 0.0901,
      "step": 7100
    },
    {
      "epoch": 3.0232558139534884,
      "grad_norm": 0.10449735075235367,
      "learning_rate": 1.8833795911358817e-05,
      "loss": 0.059,
      "step": 7150
    },
    {
      "epoch": 3.044397463002114,
      "grad_norm": 7.643954277038574,
      "learning_rate": 1.8632364939044818e-05,
      "loss": 0.0839,
      "step": 7200
    },
    {
      "epoch": 3.06553911205074,
      "grad_norm": 0.05620984733104706,
      "learning_rate": 1.843093396673082e-05,
      "loss": 0.0941,
      "step": 7250
    },
    {
      "epoch": 3.0866807610993656,
      "grad_norm": 39.93684387207031,
      "learning_rate": 1.8229502994416823e-05,
      "loss": 0.0799,
      "step": 7300
    },
    {
      "epoch": 3.1078224101479917,
      "grad_norm": 0.40063852071762085,
      "learning_rate": 1.8028072022102824e-05,
      "loss": 0.0894,
      "step": 7350
    },
    {
      "epoch": 3.1289640591966172,
      "grad_norm": 12.636268615722656,
      "learning_rate": 1.7826641049788826e-05,
      "loss": 0.06,
      "step": 7400
    },
    {
      "epoch": 3.1501057082452433,
      "grad_norm": 0.5478542447090149,
      "learning_rate": 1.762521007747483e-05,
      "loss": 0.0638,
      "step": 7450
    },
    {
      "epoch": 3.171247357293869,
      "grad_norm": 41.36751174926758,
      "learning_rate": 1.7423779105160828e-05,
      "loss": 0.11,
      "step": 7500
    },
    {
      "epoch": 3.192389006342495,
      "grad_norm": 1.9504992961883545,
      "learning_rate": 1.7222348132846832e-05,
      "loss": 0.0663,
      "step": 7550
    },
    {
      "epoch": 3.2135306553911205,
      "grad_norm": 15.822937965393066,
      "learning_rate": 1.7020917160532833e-05,
      "loss": 0.0402,
      "step": 7600
    },
    {
      "epoch": 3.234672304439746,
      "grad_norm": 18.886537551879883,
      "learning_rate": 1.6819486188218834e-05,
      "loss": 0.102,
      "step": 7650
    },
    {
      "epoch": 3.255813953488372,
      "grad_norm": 0.0555148720741272,
      "learning_rate": 1.661805521590484e-05,
      "loss": 0.066,
      "step": 7700
    },
    {
      "epoch": 3.276955602536998,
      "grad_norm": 9.131585121154785,
      "learning_rate": 1.641662424359084e-05,
      "loss": 0.0793,
      "step": 7750
    },
    {
      "epoch": 3.2980972515856237,
      "grad_norm": 0.044377513229846954,
      "learning_rate": 1.6215193271276844e-05,
      "loss": 0.0928,
      "step": 7800
    },
    {
      "epoch": 3.3192389006342493,
      "grad_norm": 0.2050805687904358,
      "learning_rate": 1.6013762298962842e-05,
      "loss": 0.0804,
      "step": 7850
    },
    {
      "epoch": 3.3403805496828753,
      "grad_norm": 0.05021526664495468,
      "learning_rate": 1.5812331326648846e-05,
      "loss": 0.0457,
      "step": 7900
    },
    {
      "epoch": 3.361522198731501,
      "grad_norm": 0.03900855407118797,
      "learning_rate": 1.5610900354334847e-05,
      "loss": 0.0523,
      "step": 7950
    },
    {
      "epoch": 3.382663847780127,
      "grad_norm": 0.09776774048805237,
      "learning_rate": 1.540946938202085e-05,
      "loss": 0.0666,
      "step": 8000
    },
    {
      "epoch": 3.4038054968287526,
      "grad_norm": 2.1499693393707275,
      "learning_rate": 1.5208038409706851e-05,
      "loss": 0.0837,
      "step": 8050
    },
    {
      "epoch": 3.4249471458773786,
      "grad_norm": 0.9218214154243469,
      "learning_rate": 1.5006607437392854e-05,
      "loss": 0.0617,
      "step": 8100
    },
    {
      "epoch": 3.446088794926004,
      "grad_norm": 53.07388687133789,
      "learning_rate": 1.4805176465078857e-05,
      "loss": 0.0938,
      "step": 8150
    },
    {
      "epoch": 3.46723044397463,
      "grad_norm": 0.17591817677021027,
      "learning_rate": 1.4603745492764856e-05,
      "loss": 0.0554,
      "step": 8200
    },
    {
      "epoch": 3.488372093023256,
      "grad_norm": 0.012334007769823074,
      "learning_rate": 1.4402314520450859e-05,
      "loss": 0.0689,
      "step": 8250
    },
    {
      "epoch": 3.5095137420718814,
      "grad_norm": 0.0312128197401762,
      "learning_rate": 1.420088354813686e-05,
      "loss": 0.0575,
      "step": 8300
    },
    {
      "epoch": 3.5306553911205074,
      "grad_norm": 0.03792209550738335,
      "learning_rate": 1.3999452575822863e-05,
      "loss": 0.0408,
      "step": 8350
    },
    {
      "epoch": 3.5517970401691334,
      "grad_norm": 0.423944354057312,
      "learning_rate": 1.3798021603508866e-05,
      "loss": 0.0709,
      "step": 8400
    },
    {
      "epoch": 3.572938689217759,
      "grad_norm": 1.0619020462036133,
      "learning_rate": 1.3596590631194868e-05,
      "loss": 0.0366,
      "step": 8450
    },
    {
      "epoch": 3.5940803382663846,
      "grad_norm": 9.936210632324219,
      "learning_rate": 1.339515965888087e-05,
      "loss": 0.0849,
      "step": 8500
    },
    {
      "epoch": 3.6152219873150107,
      "grad_norm": 0.018426863476634026,
      "learning_rate": 1.3193728686566872e-05,
      "loss": 0.0948,
      "step": 8550
    },
    {
      "epoch": 3.6363636363636362,
      "grad_norm": 2.73494815826416,
      "learning_rate": 1.2992297714252872e-05,
      "loss": 0.1365,
      "step": 8600
    },
    {
      "epoch": 3.6575052854122623,
      "grad_norm": 23.861173629760742,
      "learning_rate": 1.2790866741938874e-05,
      "loss": 0.126,
      "step": 8650
    },
    {
      "epoch": 3.678646934460888,
      "grad_norm": 6.105389595031738,
      "learning_rate": 1.2589435769624877e-05,
      "loss": 0.0555,
      "step": 8700
    },
    {
      "epoch": 3.699788583509514,
      "grad_norm": 0.06219272315502167,
      "learning_rate": 1.238800479731088e-05,
      "loss": 0.0627,
      "step": 8750
    },
    {
      "epoch": 3.7209302325581395,
      "grad_norm": 2.748812198638916,
      "learning_rate": 1.2186573824996881e-05,
      "loss": 0.099,
      "step": 8800
    },
    {
      "epoch": 3.7420718816067655,
      "grad_norm": 33.85283279418945,
      "learning_rate": 1.1985142852682884e-05,
      "loss": 0.0875,
      "step": 8850
    },
    {
      "epoch": 3.763213530655391,
      "grad_norm": 0.614495575428009,
      "learning_rate": 1.1783711880368885e-05,
      "loss": 0.0729,
      "step": 8900
    },
    {
      "epoch": 3.7843551797040167,
      "grad_norm": 60.40226364135742,
      "learning_rate": 1.1582280908054888e-05,
      "loss": 0.0789,
      "step": 8950
    },
    {
      "epoch": 3.8054968287526427,
      "grad_norm": 5.22035026550293,
      "learning_rate": 1.138084993574089e-05,
      "loss": 0.0562,
      "step": 9000
    },
    {
      "epoch": 3.8266384778012688,
      "grad_norm": 0.07584231346845627,
      "learning_rate": 1.117941896342689e-05,
      "loss": 0.0685,
      "step": 9050
    },
    {
      "epoch": 3.8477801268498943,
      "grad_norm": 1.5760775804519653,
      "learning_rate": 1.0977987991112892e-05,
      "loss": 0.0477,
      "step": 9100
    },
    {
      "epoch": 3.86892177589852,
      "grad_norm": 2.227609157562256,
      "learning_rate": 1.0776557018798895e-05,
      "loss": 0.0909,
      "step": 9150
    },
    {
      "epoch": 3.890063424947146,
      "grad_norm": 0.11653320491313934,
      "learning_rate": 1.0575126046484896e-05,
      "loss": 0.0735,
      "step": 9200
    },
    {
      "epoch": 3.9112050739957716,
      "grad_norm": 1.2450528144836426,
      "learning_rate": 1.0373695074170899e-05,
      "loss": 0.0647,
      "step": 9250
    },
    {
      "epoch": 3.9323467230443976,
      "grad_norm": 20.54642105102539,
      "learning_rate": 1.01722641018569e-05,
      "loss": 0.0584,
      "step": 9300
    },
    {
      "epoch": 3.953488372093023,
      "grad_norm": 0.009710006415843964,
      "learning_rate": 9.970833129542903e-06,
      "loss": 0.0562,
      "step": 9350
    },
    {
      "epoch": 3.974630021141649,
      "grad_norm": 3.610309362411499,
      "learning_rate": 9.769402157228904e-06,
      "loss": 0.0461,
      "step": 9400
    },
    {
      "epoch": 3.995771670190275,
      "grad_norm": 0.08612249046564102,
      "learning_rate": 9.567971184914907e-06,
      "loss": 0.0749,
      "step": 9450
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8806301543666737,
      "eval_f1": 0.8804747834679874,
      "eval_loss": 0.7050864696502686,
      "eval_runtime": 77.0619,
      "eval_samples_per_second": 122.733,
      "eval_steps_per_second": 15.351,
      "step": 9460
    },
    {
      "epoch": 4.016913319238901,
      "grad_norm": 0.524811327457428,
      "learning_rate": 9.36654021260091e-06,
      "loss": 0.0618,
      "step": 9500
    },
    {
      "epoch": 4.038054968287526,
      "grad_norm": 0.09307747334241867,
      "learning_rate": 9.16510924028691e-06,
      "loss": 0.0146,
      "step": 9550
    },
    {
      "epoch": 4.059196617336152,
      "grad_norm": 0.028939682990312576,
      "learning_rate": 8.963678267972912e-06,
      "loss": 0.0365,
      "step": 9600
    },
    {
      "epoch": 4.080338266384778,
      "grad_norm": 0.01845940388739109,
      "learning_rate": 8.762247295658914e-06,
      "loss": 0.0169,
      "step": 9650
    },
    {
      "epoch": 4.101479915433404,
      "grad_norm": 6.466153144836426,
      "learning_rate": 8.560816323344917e-06,
      "loss": 0.0392,
      "step": 9700
    },
    {
      "epoch": 4.12262156448203,
      "grad_norm": 0.008616884239017963,
      "learning_rate": 8.359385351030918e-06,
      "loss": 0.0171,
      "step": 9750
    },
    {
      "epoch": 4.143763213530655,
      "grad_norm": 0.006649190094321966,
      "learning_rate": 8.15795437871692e-06,
      "loss": 0.0301,
      "step": 9800
    },
    {
      "epoch": 4.164904862579281,
      "grad_norm": 0.006834336556494236,
      "learning_rate": 7.956523406402922e-06,
      "loss": 0.02,
      "step": 9850
    },
    {
      "epoch": 4.186046511627907,
      "grad_norm": 0.01842178963124752,
      "learning_rate": 7.755092434088925e-06,
      "loss": 0.0366,
      "step": 9900
    },
    {
      "epoch": 4.207188160676533,
      "grad_norm": 73.09359741210938,
      "learning_rate": 7.553661461774926e-06,
      "loss": 0.0281,
      "step": 9950
    },
    {
      "epoch": 4.2283298097251585,
      "grad_norm": 0.005701975431293249,
      "learning_rate": 7.352230489460928e-06,
      "loss": 0.0376,
      "step": 10000
    },
    {
      "epoch": 4.249471458773784,
      "grad_norm": 0.0682598128914833,
      "learning_rate": 7.150799517146931e-06,
      "loss": 0.0611,
      "step": 10050
    },
    {
      "epoch": 4.2706131078224105,
      "grad_norm": 0.13825981318950653,
      "learning_rate": 6.949368544832932e-06,
      "loss": 0.0094,
      "step": 10100
    },
    {
      "epoch": 4.291754756871036,
      "grad_norm": 0.08243934065103531,
      "learning_rate": 6.747937572518934e-06,
      "loss": 0.0538,
      "step": 10150
    },
    {
      "epoch": 4.312896405919662,
      "grad_norm": 0.01673721708357334,
      "learning_rate": 6.546506600204936e-06,
      "loss": 0.0244,
      "step": 10200
    },
    {
      "epoch": 4.334038054968287,
      "grad_norm": 0.0745333880186081,
      "learning_rate": 6.345075627890938e-06,
      "loss": 0.048,
      "step": 10250
    },
    {
      "epoch": 4.355179704016914,
      "grad_norm": 10.626760482788086,
      "learning_rate": 6.143644655576939e-06,
      "loss": 0.0479,
      "step": 10300
    },
    {
      "epoch": 4.376321353065539,
      "grad_norm": 0.02277209609746933,
      "learning_rate": 5.942213683262942e-06,
      "loss": 0.0121,
      "step": 10350
    },
    {
      "epoch": 4.397463002114165,
      "grad_norm": 0.008690103888511658,
      "learning_rate": 5.740782710948944e-06,
      "loss": 0.0313,
      "step": 10400
    },
    {
      "epoch": 4.4186046511627906,
      "grad_norm": 1.9618573188781738,
      "learning_rate": 5.539351738634946e-06,
      "loss": 0.0246,
      "step": 10450
    },
    {
      "epoch": 4.439746300211416,
      "grad_norm": 0.012808127328753471,
      "learning_rate": 5.337920766320948e-06,
      "loss": 0.0345,
      "step": 10500
    },
    {
      "epoch": 4.460887949260043,
      "grad_norm": 0.09436476230621338,
      "learning_rate": 5.13648979400695e-06,
      "loss": 0.0418,
      "step": 10550
    },
    {
      "epoch": 4.482029598308668,
      "grad_norm": 0.14649486541748047,
      "learning_rate": 4.935058821692952e-06,
      "loss": 0.0135,
      "step": 10600
    },
    {
      "epoch": 4.503171247357294,
      "grad_norm": 4.290856838226318,
      "learning_rate": 4.733627849378954e-06,
      "loss": 0.0243,
      "step": 10650
    },
    {
      "epoch": 4.524312896405919,
      "grad_norm": 0.044257752597332,
      "learning_rate": 4.5321968770649556e-06,
      "loss": 0.0404,
      "step": 10700
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 5.622796535491943,
      "learning_rate": 4.3307659047509575e-06,
      "loss": 0.03,
      "step": 10750
    },
    {
      "epoch": 4.5665961945031714,
      "grad_norm": 0.02219301648437977,
      "learning_rate": 4.129334932436959e-06,
      "loss": 0.0384,
      "step": 10800
    },
    {
      "epoch": 4.587737843551797,
      "grad_norm": 0.0536770224571228,
      "learning_rate": 3.927903960122962e-06,
      "loss": 0.0271,
      "step": 10850
    },
    {
      "epoch": 4.608879492600423,
      "grad_norm": 0.006531053222715855,
      "learning_rate": 3.7264729878089637e-06,
      "loss": 0.0264,
      "step": 10900
    },
    {
      "epoch": 4.630021141649049,
      "grad_norm": 1.4789477586746216,
      "learning_rate": 3.525042015494966e-06,
      "loss": 0.0101,
      "step": 10950
    },
    {
      "epoch": 4.651162790697675,
      "grad_norm": 0.00655203266069293,
      "learning_rate": 3.3236110431809675e-06,
      "loss": 0.0203,
      "step": 11000
    },
    {
      "epoch": 4.6723044397463,
      "grad_norm": 0.004308605566620827,
      "learning_rate": 3.12218007086697e-06,
      "loss": 0.0123,
      "step": 11050
    },
    {
      "epoch": 4.693446088794926,
      "grad_norm": 51.386962890625,
      "learning_rate": 2.9207490985529713e-06,
      "loss": 0.0379,
      "step": 11100
    },
    {
      "epoch": 4.7145877378435515,
      "grad_norm": 10.360078811645508,
      "learning_rate": 2.7193181262389737e-06,
      "loss": 0.0332,
      "step": 11150
    },
    {
      "epoch": 4.735729386892178,
      "grad_norm": 0.008082209154963493,
      "learning_rate": 2.5178871539249756e-06,
      "loss": 0.062,
      "step": 11200
    },
    {
      "epoch": 4.7568710359408035,
      "grad_norm": 0.25012287497520447,
      "learning_rate": 2.3164561816109775e-06,
      "loss": 0.0418,
      "step": 11250
    },
    {
      "epoch": 4.778012684989429,
      "grad_norm": 34.425777435302734,
      "learning_rate": 2.1150252092969794e-06,
      "loss": 0.0357,
      "step": 11300
    },
    {
      "epoch": 4.799154334038055,
      "grad_norm": 27.468280792236328,
      "learning_rate": 1.9135942369829813e-06,
      "loss": 0.0142,
      "step": 11350
    },
    {
      "epoch": 4.82029598308668,
      "grad_norm": 0.007640565279871225,
      "learning_rate": 1.7121632646689833e-06,
      "loss": 0.0357,
      "step": 11400
    },
    {
      "epoch": 4.841437632135307,
      "grad_norm": 0.3766312897205353,
      "learning_rate": 1.5107322923549852e-06,
      "loss": 0.0173,
      "step": 11450
    },
    {
      "epoch": 4.862579281183932,
      "grad_norm": 55.54092025756836,
      "learning_rate": 1.309301320040987e-06,
      "loss": 0.013,
      "step": 11500
    },
    {
      "epoch": 4.883720930232558,
      "grad_norm": 0.005660280119627714,
      "learning_rate": 1.1078703477269892e-06,
      "loss": 0.0268,
      "step": 11550
    },
    {
      "epoch": 4.904862579281184,
      "grad_norm": 0.16642794013023376,
      "learning_rate": 9.064393754129912e-07,
      "loss": 0.0474,
      "step": 11600
    },
    {
      "epoch": 4.92600422832981,
      "grad_norm": 31.22645378112793,
      "learning_rate": 7.050084030989931e-07,
      "loss": 0.0384,
      "step": 11650
    },
    {
      "epoch": 4.947145877378436,
      "grad_norm": 3.140580892562866,
      "learning_rate": 5.035774307849951e-07,
      "loss": 0.0466,
      "step": 11700
    },
    {
      "epoch": 4.968287526427061,
      "grad_norm": 5.242565155029297,
      "learning_rate": 3.02146458470997e-07,
      "loss": 0.0267,
      "step": 11750
    },
    {
      "epoch": 4.989429175475687,
      "grad_norm": 19.228605270385742,
      "learning_rate": 1.0071548615699901e-07,
      "loss": 0.0462,
      "step": 11800
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.8766123916261366,
      "eval_f1": 0.8763261703041049,
      "eval_loss": 0.80043625831604,
      "eval_runtime": 77.141,
      "eval_samples_per_second": 122.607,
      "eval_steps_per_second": 15.336,
      "step": 11825
    }
  ],
  "logging_steps": 50,
  "max_steps": 11825,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6256104070026240.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": {
    "learning_rate": 4.7638424952260535e-05,
    "num_train_epochs": 5,
    "per_device_train_batch_size": 16,
    "weight_decay": 0.0642295884958588
  }
}
